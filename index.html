<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>MyNote</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="MyNote">
<meta property="og:url" content="http://mynote.ai/index.html">
<meta property="og:site_name" content="MyNote">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Chen min">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="MyNote" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">MyNote</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">我的AI笔记</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://mynote.ai"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-20240218-散步时的自说自话" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/02/18/20240218-%E6%95%A3%E6%AD%A5%E6%97%B6%E7%9A%84%E8%87%AA%E8%AF%B4%E8%87%AA%E8%AF%9D/" class="article-date">
  <time class="dt-published" datetime="2024-02-18T13:45:37.000Z" itemprop="datePublished">2024-02-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/02/18/20240218-%E6%95%A3%E6%AD%A5%E6%97%B6%E7%9A%84%E8%87%AA%E8%AF%B4%E8%87%AA%E8%AF%9D/">20240218-夜间散步时的自说自话</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>讲话人1 - 0:00</p>
<p>一个人在路上瞎说点什么，然后拿手表来记录，吧刚刚说了一句话，这是一棵树，他还活着那是两个人，他们坐在地上今天不知道怎么的，情绪在8点多，达到了一个比较厌恶或者是说沉重，突然觉得这样子的生活过得有点没意思，具体用哪没有意思，呢说不上来。</p>
<p>讲话人1 - 0:48</p>
<p>现在心中想着的是那个 wait but why动画中地球对着那个火柴人说“走去过你想要的生活”。觉得现在的生活对我来说好像有点束缚，我不知道我这一天到底在做什么，我真不知道，是没有记录，没有进步还是怎么的？激情好像有点退却。</p>
<p>讲话人1 - 1:25</p>
<p>现在身旁的树有树叶，噢对了，我还看了车的视频，问界9五十万，有可能我心里的压力有一部分也是来自于那里，就是50万，呀唉我得赚多久才能赚到这部分钱？想暴富了，突然间也不是突然间吧。往前走，前面是一片黑暗。</p>
<p>讲话人1 - 2:08</p>
<p>就往前吧多走几步，也不会怎么办？我的右手小拇指呀它盘着了，我一伸直它就咔一声咔一声咔一声的响，那前方是什么路？</p>
<p>讲话人1 - 2:38</p>
<p>我过去我其实不是很懂，我现在就相当于拿着一个手表在这边自说自话在说什么，啊非常感谢小李今天给我打了第二通电话，他很关心我的情绪，让我感觉到我被人关心，想着昨天看了一些股票相关的消息，想着买些猪肉股，买些新能源，买些港股中概互联的ETF，想着也许能通过这些交易赚一些钱，赚钱来干嘛？</p>
<p>讲话人1 - 3:44</p>
<p>挣钱来让自己开心。钱不会让我开心，但是不纠结也许会让我开心一点，之前好想买个投影，现在呢现在不知道了，就像我之前好想买这个手表，好想买那个手机一样，当我拥有它了，它成了一种方式，没有当时我寄希望于它那样对我来说有那么大的帮助，但它也不是一无是处，比如这个手表在我手机快没电的时候，我能拿它来录个音，这大概也是极好的，但在平常他在我身边好像什么都没有作用，谁知道呢说到这里我每天的生活在干嘛？</p>
<p>讲话人1 - 4:49</p>
<p>呢我有点担心自己，没有反省自己的生活，自己的右手的小拇指有点疼，自己没办法减下肥，晚上一有点饥饿感就又想去吃东西，这应该是没有意志力吧。或者我也不知道是怎么回事，好不容易现在有个机会对着手表说一下这些话，AGI会不会替换掉我们的生活？半导体的那些公式太复杂了，电学呀一点都不会，会不了一点啊太难了。</p>
<p>讲话人1 - 6:22</p>
<p>前路其实有点长，我意识到自己有些普通，甚至于说自己有点平凡，嗯今天没有后面的豪言壮志了，就和这种情绪在一起待一会儿，吧它可能是个很短的一句话，把最后一句话送给自己。再会。</p>
<blockquote>
<p>“去吧，去创造自己的生活”</p>
</blockquote>
<p><img src="/images/492fcb9f479780f22c8baf499650a85.jpg" alt="去吧，去创造自己的生活"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2024/02/18/20240218-%E6%95%A3%E6%AD%A5%E6%97%B6%E7%9A%84%E8%87%AA%E8%AF%B4%E8%87%AA%E8%AF%9D/" data-id="clsrl52ot0000eox17klcfflj" data-title="20240218-夜间散步时的自说自话" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA/" rel="tag">个人</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-LeetCode26" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/23/LeetCode26/" class="article-date">
  <time class="dt-published" datetime="2020-11-23T11:37:45.000Z" itemprop="datePublished">2020-11-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/11/23/LeetCode26/">LeetCode26</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>关键词：数组去重<br>题目描述：</p>
<blockquote>
<p>Given a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length.<br>Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory.</p>
</blockquote>
<p>这道题需要更改原始输入的数组并且返回去重后的数组长度。<br>分为两部分来思考：</p>
<ol>
<li>去重数组长度计算<br>注意到这里的输入数组是排好序的数组。所以可以用指针从头开始比较。并设置去重后的数组长度为count&#x3D;0. 用count也可以作为数组的指针，来表示数组在count这个位置的数值。<br>肯定要遍历整个数组，用一个for循环和i指针来做。<br>在这里我一开始的思路是判断count指针和i指针大小，如果count指针所指的数小则将count++。最后count就是要求的数组长度。</li>
<li>更改原始输入数组<br>题目要求必须在原始数组上进行更改而不能新建一个数组。有一个隐含前提，去重数组的长度一定小于等于原始数组。那么，我们可以直接将大于当前指针的数放入前一个已经去重的数之后。<br>所以我们需要一个指针来保存去重列表的末尾部分,恰好这个指针就是count，当i指针遍历整个数组遇到一个新的数（只需要比count的大）时，可以将这个数放入count之后的格子里，直到i遍历到达了整个原始数组的尾部。</li>
</ol>
<p>需要考虑边界条件。当输入数组nums的长度为0和1时，这个算法是否能够给出0,1的返回值？不能。count&#x3D;0的初始设置在nums.length&#x3D;1时还是等于0.因为count&#x3D;&#x3D;i&#x3D;&#x3D;0，并不会进入自增的过程。可以考虑返回count+1，然后在算法顶端加一个判断条件。数组的长度是否为0，如果是0，直接返回0就好了。</p>
<p>Java版本的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">removeDuplicates</span><span class="params">(<span class="type">int</span>[] nums)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(nums.length == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt; nums.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums[count] &lt; nums[i])&#123;</span><br><span class="line">            nums[count+<span class="number">1</span>] = nums[i];</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> count+<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/11/23/LeetCode26/" data-id="clnhnlj120006zox12gvv9vf7" data-title="LeetCode26" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Leet-Code/" rel="tag">Leet Code</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-学习Kaldi：中文Aishell项目（上）" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/" class="article-date">
  <time class="dt-published" datetime="2020-11-23T11:36:51.000Z" itemprop="datePublished">2020-11-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/">学习Kaldi：中文Aishell项目（上）</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>这篇文章是学习Kaldi的第二篇。对应SUSTech CS310课程的Lab6和Lab7。<br>第一篇里探索了如何对toy language（仅包含两个单音素单词）进行语言模型的建模。至于训练和解码的部分，时间条件和理解能力暂时不允许去整理。<br>本篇文章的主要目标是理解复杂的中文多音素语言模型和使用AiShell语料集来真实的训练出一个可用的中文语音识别模型。完整的AiShell例子包含GMM-HMM和神经网络。Lab6先展示了GMM-HMM后的结果。Lab7则补充了神经网络。</p>
<h2 id="AiShell描述和下载"><a href="#AiShell描述和下载" class="headerlink" title="AiShell描述和下载"></a>AiShell描述和下载</h2><p>AiShell 是 ？？公司开源的中文普通话语料集。400个来自不同方言区的人参与录制， 录制的条件是在室内使用高保真的麦克风，音频降采样到16000Hz。<br>&#x2F;&#x2F;中文文字脚本95%的准确度<br>&#x2F;&#x2F;170小时的语料。划分为85%的训练集，10%的开发集（作用？），5%的测试集。在上课的时候我被录制语料的成本吓到了，2000小时的语料大约需要100万人民币的费用。<br>AiShell语料集可以免费由于学术目的。</p>
<p>语料集下载<br>Kaldi中包含Aishell的示例脚本。在<code>kaldi/egs/aishell/s5</code>中。下文所有的文件都在该目录之下。<br>下载语料集的脚本包含在<code>run.sh</code>中。<br>先安装好语言模型的工具才能运行<code>run.sh</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run ./install_kaldi_lm.sh &amp;&amp; source ../env.sh</span><br></pre></td></tr></table></figure>
<p>上一篇文章没有说每一个项目下的s5文件夹中有什么，在网上找到了别人写的一个总结：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6ab663601da8">kaldi 源码分析(三) - run.pl 分析</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cmd.sh                     # 并行执行命令，通常分 run.pl, queue.pl 两种</span><br><span class="line">config                       # 参数定制化配置文件， mfcc, decode, cmvn 等配置文件</span><br><span class="line">local                         # 工程定制化内容</span><br><span class="line">path.sh                    # 环境变量相关脚本</span><br><span class="line">run.sh                      # 整体流程控制脚本，主入口脚本</span><br><span class="line">steps                       # 存放单一步骤执行的脚本</span><br><span class="line">utils                         # 存放解析文件，预处理等相</span><br><span class="line">关工具的脚本</span><br></pre></td></tr></table></figure>
<p>最重要的入口脚本是run.sh。包含所有脚本。如果要在本地运行，需要修改这个脚本。把其中的<code>queue.pl</code>改成<code>run.pl</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export train_cmd=&quot;run.pl&quot; </span><br><span class="line">export decode_cmd=run.pl </span><br><span class="line">export mkgraph_cmd=&quot;run.pl&quot;</span><br></pre></td></tr></table></figure>
<p>先做Lab6，注释掉神经网络训练部分。为了对比加不加神经网络对最后的识别准确率有多大的影响。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># nnet3</span><br><span class="line">#local/nnet3/run_tdnn.sh</span><br><span class="line"># chain</span><br><span class="line">#local/chain/run_tdnn.sh</span><br></pre></td></tr></table></figure>



<h2 id="运行run-sh脚本，一步到位"><a href="#运行run-sh脚本，一步到位" class="headerlink" title="运行run.sh脚本，一步到位"></a>运行run.sh脚本，一步到位</h2><p>在上一篇文章中，主要讲了kaldi的工作流程，复杂一点的项目除了要考虑多音素的对齐以外？基本流程是差不多的。先运行整体流程脚本run.sh看一下效果。然后再具体深入进脚本中看有哪些关键步骤。</p>
<p>你是否遇到过连接远程服务器跑训练，然后网络掉线杀掉了正在跑的进程？我遇到过，后来主要使用nohup来避免这个问题。课件里推荐使用screen来避免远程登陆进程被杀掉后，训练进程也停止的问题。screen的原理不是本篇文章关心的重点。<br>加上screen后运行run.sh：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">screen -S run</span><br><span class="line">run ./run.sh</span><br></pre></td></tr></table></figure>
<p>就能看到脚本在一个新的页面输出内容了。<br>如果要结束进程<code> ctrl a + d</code>&#x2F;&#x2F;我其实不喜欢这个命令，因为很经常使用ctrl+a来编辑命令，两个快捷键冲突。</p>
<h2 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h2><p>中文语音识别的准确度通常使用CER（Char Error Rate）来表示。因为中文中字是最小语义单位，而英文中词是基本语义单位。<br>和上一篇文章差不多的命令。脚本的运行结果保存在了exp目录下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for x in exp/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br></pre></td></tr></table></figure>
<p>训练出来的结果如下：<br><img src="/images/1246.png" alt="训练结果"></p>
<p>可以<code>cat RESULTS</code>，和官方跑出来的结果做一下对比。<br><img src="/images/1247.png" alt="RESULTS"><br>需要注意的是，和上篇文章的实验不一样的是，输出的结果是多行的，因为执行了多次的实验，上面的脚本输出的是每次实验最好的结果。<br>我自己跑出来的最好结果是tri5a的cer_14_0.5而RESULTS中的GMM-HMM模型中最好的结果是tri5a的cer_13_0.5。两者CER都是12.12。每次实验本身都有一定的随机性。结果有一些误差是没问题的。为了确认模型有被正确的训练，查看自己结果的<code>tri5a/decode_test/cer_13_0.5</code>的CER是12.18，恰好不是最优解而已。这里的13和14是lmwt（语言模型权重）。具体的可以看上一篇文章。<br><img src="/images/1248.png" alt="cer_13_0.5"></p>
<h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><p>使用命令<code>cat run.sh | grep &quot;#&quot;</code>将run.sh脚本中的环节注释提取打印出来。其中倒数2，4行是我们在一开始注释掉的。可以看到基本可以分为准备、训练和获取结果三个部分。<br><img src="/images/1249.png" alt="run.sh注释部分"></p>
<h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><ol>
<li>下载语料集<br>需要注意的是aishell语料集有大概20GB的大小。意味着需要很长的时间才能下载下来。我是直接用服务器里提前下好的语料集。<br><img src="/images/1250.png" alt="aishell目录概览"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/download_and_untar.sh $data $data_url data_aishell || exit 1;</span><br></pre></td></tr></table></figure>
这里的 <code>a || b</code>是一个逻辑符号，代表着如果a执行失败则执行b。这里要放一个小插曲。去年面试阿里云的实习项目时，面试官开头就问了如何知道上一条linux命令是否成功执行。我当时不知道，现在要知道了。就是看变量<code>$?</code>的值，如果为0代表成功执行。这里的<code>exit 1</code>终止当前进程并且将<code>$?</code>设置为1。表示不成功执行。<br><code>$data</code> 是aishell在本机的位置，既可以新建一个空目录来下载，也可以指定到已经下好的路径，aishell 分为<code>resource_aishell</code>和<code>data_aishell</code>两部分来下载，脚本会通过检查每一个部分下是否有<code>.complete</code>文件来判断当前部分是否下载完全。如果没有才会到指定网址下载。</li>
<li>Lexicon Preparation<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/aishell_prepare_dict.sh $data/resource_aishell || exit 1;</span><br></pre></td></tr></table></figure>
这个脚本的功能主要是将<code>resource_aishell</code>下的<code>lexicon.txt</code>复制到<code>data/local/dict</code>中。并且提取出<code>nonsilence_phones.txt</code>、<code>optional_silence.txt   </code>、<code>silence_phones.txt</code>和<code>extra_questions.txt</code>。用到了很多awk和perl的脚本。没看懂。（要是看懂了，第一次assignment就不会搞砸了）<br>那就要求自己看懂把。</li>
</ol>
<p><img src="/images/1251.png" alt="lexicon.txt"></p>
<p><img src="/images/1252.png" alt="提取extra_questions.txt的代码"></p>
<p><img src="/images/1253.png" alt="extra_questions.txt部分内容"></p>
<p><img src="/images/1254.png" alt="提取nonsilence_phones.txt代码"><br>每行代表一组相同的base phone,包含各种不同的重音或者声调。<br><img src="/images/1255.png" alt="nonsilence_phones.txt部分内容"></p>
<ol start="3">
<li>Data preparation<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/aishell_data_prep.sh $data/data_aishell/wav $data/data_aishell/transcript || exit 1;</span><br></pre></td></tr></table></figure>
<code>$data/data_aishell/wav</code>目录下放着的是音频文件。其中有两级目录<code>speaker/filename.wav</code>。<br><code>$data/data_aishell/transcript</code>目录下放着的是<code>aishell_transcript_v0.8.txt</code>文字翻录。<br>这个shell脚本的功能是将<code>$data/data_aishell/wav</code>下的 <code>train</code>,<code>test</code>,<code>dev</code>分别建立索引。并且建立Kaldi能够理解的语料格式。具体有些什么可以参考上一篇文章和下面这一段脚本。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Transcriptions preparation</span><br><span class="line">for dir in $train_dir $dev_dir $test_dir; do</span><br><span class="line">  echo Preparing $dir transcriptions</span><br><span class="line">  # 将当前集合目录下的wav的文件名提取出来作为utt_id</span><br><span class="line">  sed -e &#x27;s/\.wav//&#x27; $dir/wav.flist | awk -F &#x27;/&#x27; &#x27;&#123;print $NF&#125;&#x27; &gt; $dir/utt.list</span><br><span class="line">  # 根据目录结构建立utt2spk的关系</span><br><span class="line">  sed -e &#x27;s/\.wav//&#x27; $dir/wav.flist | awk -F &#x27;/&#x27; &#x27;&#123;i=NF-1;printf(&quot;%s %s\n&quot;,$NF,$i)&#125;&#x27; &gt; $dir/utt2spk_all</span><br><span class="line">  # 按列合并utt.list和wav.flist，达到对音频文件的映射。</span><br><span class="line">  paste -d&#x27; &#x27; $dir/utt.list $dir/wav.flist &gt; $dir/wav.scp_all</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $aishell_text &gt; $dir/transcripts.txt</span><br><span class="line">  awk &#x27;&#123;print $1&#125;&#x27; $dir/transcripts.txt &gt; $dir/utt.list</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $dir/utt2spk_all | sort -u &gt; $dir/utt2spk</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $dir/wav.scp_all | sort -u &gt; $dir/wav.scp</span><br><span class="line">  sort -u $dir/transcripts.txt &gt; $dir/text</span><br><span class="line">  utils/utt2spk_to_spk2utt.pl $dir/utt2spk &gt; $dir/spk2utt</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="4-Phone-sets-questions-L-compilation"><a href="#4-Phone-sets-questions-L-compilation" class="headerlink" title="4. Phone sets, questions, L compilation"></a>4. Phone sets, questions, L compilation</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">utils/prepare_lang.sh --position-dependent-phones false data/local/dict \</span><br><span class="line">    &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang data/lang || exit 1;</span><br></pre></td></tr></table></figure>
<p>上面shell脚本的目的是创建L.fst，音素模型，其中fst是Finite State Transducers（有限状态转换器）的缩写。找到这篇<a target="_blank" rel="noopener" href="https://blog.csdn.net/DuishengChen/article/details/52473918">Kaldi学习笔记 – 构建字典FST脚本 – prepare_lang.sh 关键内容解析</a>详细的说明了这个脚本的工作。而<a target="_blank" rel="noopener" href="https://blog.csdn.net/mengjianmuzi/article/details/99499343">关于prepare_lang的一点理解</a>给脚本进行了一些翻译和注释。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4ad2add56b25">Kaldi中FST(Finite State Transducer)含义及其可视化</a><br>L.fst: 音素词典（Phonetic Dictionary or Lexicon）模型，phone symbols作为输入，word symbols作为输出，如图Figure 1所示。<br><img src="/images/1256.png" alt="Figure 1 L.fst结构"><br>L_disambig.fst是为了消除模棱两可（disambiguation）而引入的模型，表述为 the lexicon with disambiguation symbols。分歧的情况如：一个词是另一个词的前缀，cat 和 cats在同一个词典中，则需要”k ae t #1”； 有同音的词，red: “r eh d #1”, read: “r eh d #2”。</p>
</blockquote>
<p>我一直疑惑<code>lexiconp.txt</code>是怎么生成的，查了好久。结果竟然只是一段在词和音素之间插入1.0的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if [[ ! -f $srcdir/lexiconp.txt ]]; then</span><br><span class="line">  echo &quot;**Creating $srcdir/lexiconp.txt from $srcdir/lexicon.txt&quot;</span><br><span class="line">  perl -ape &#x27;s/(\S+\s+)(.+)/$&#123;1&#125;1.0\t$2/;&#x27; &lt; $srcdir/lexicon.txt &gt; $srcdir/lexiconp.txt || exit 1;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p><img src="/images/1257.png" alt="lexiconp.txt"><br>那么L.fst是怎么得到的呢？<br>通过<code>make_lexicon_fst.py</code>（现有的博客都说是.pl结尾，可能kaldi重构了）。还有一个消歧义的过程。具体的就看不懂了。<a target="_blank" rel="noopener" href="https://shiweipku.gitbooks.io/chinese-doc-of-kaldi/content/decoding_graph_test.html">解码图创建示例（测试阶段）</a>里有较为详细的文档讲解。</p>
<h4 id="5-LM-training"><a href="#5-LM-training" class="headerlink" title="5. LM training"></a>5. LM training</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/aishell_train_lms.sh || exit 1;</span><br></pre></td></tr></table></figure>
<p>这个shell脚本读取<code>data/local/train/text</code>,<code>data/local/dict/lexicon.txt</code><br>得到text的计数文件<code>word.counts</code>并以<code>word.counts</code>为基础添加<code>lexicon.txt</code>中的字（除了SIL）出现的次数到<code>unigram.counts</code>中。我就没深入看下去了，期间用到的脚本文件有:<code>get_word_map.pl</code>、<code>train_lm.sh --arpa --lmtype 3gram-mincount $dir || exit 1</code>;这个步骤的结果保存在<code>data/local/lm/3gram-mincount/lm_unpruned.gz</code>中。</p>
<h4 id="6-G-compilation-check-LG-composition"><a href="#6-G-compilation-check-LG-composition" class="headerlink" title="6. G compilation, check LG composition"></a>6. G compilation, check LG composition</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">utils/format_lm.sh data/lang data/local/lm/3gram-mincount/lm_unpruned.gz \</span><br><span class="line">    data/local/dict/lexicon.txt data/lang_test || exit 1;</span><br></pre></td></tr></table></figure>
<p>这个步骤是编译G.fst并将LG串联起来。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4ad2add56b25">Kaldi中FST(Finite State Transducer)含义及其可视化</a><br>G.fst: 语言模型，大部分是FSA（finite state acceptor, i.e. 每个arc的输入输出是相同的），如图Figure 2所示。<br><img src="/images/1258.png" alt="Figure 2 G.fst结构（由指令词识别1-gram语法产生，disambiguation symbol #0 未加入）
"></p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://hupeng.me/articles/25.html">kaldi 训练 aishell 解析</a><br>utils&#x2F;format_lm.sh:上述的语言工具基于第三方工具，为ARPA-format,脚本的作业是将其转换为fst，方便与之前的字典fst(L.fst)结合，发挥fst的优势。脚本最后会检测G.fst中是否存在没有单词的空回环，如果存在会报错，因为这会导致后续HLG determinization的出现错误。<br>脚本utils&#x2F;format_lm.sh解决把ARPA格式的语言模型转换成OpenFST格式类型。脚本用法如下：<br>Usage: utils&#x2F;format_lm.sh <lang_dir> <arpa-LM> <lexicon> <out_dir><br>E.g.: utils&#x2F;format_lm.sh data&#x2F;lang data&#x2F;local&#x2F;lm&#x2F;foo.kn.gz data&#x2F;local&#x2F;dict&#x2F;lexicon.txt data&#x2F;lang_test<br>Convert ARPA-format language models to FSTs.<br>这个脚本的一些关键命令如下：<br>Kaldi程序arpa2fst将ARPA格式的语言模型转换成一个加权有限状态转移机（实际上是接收机）。</p>
</blockquote>
<p>流程很复杂，未来可能再把L.fst，LM training，G.fst， LG composition另起一篇。（就是说现在时间条件不允许深入）</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>训练的环节开始我就读不懂了。主要是逻辑和概念不懂。也不浪费时间了。简单的去了解一下输入输出和功能。</p>
<h4 id="1-MFCC-特征生成"><a href="#1-MFCC-特征生成" class="headerlink" title="1. MFCC 特征生成"></a>1. MFCC 特征生成</h4><p>这个环节和yesno项目的没有不同。主要就是获得train,test, dev三个集合的归一化的梅尔倒谱系数。最后修复排序错误，并会移除那些被指明需要特征数据或标注，但是却找不到被需要的数据的那些发音（utterances）。</p>
<h4 id="2-训练单音素模型"><a href="#2-训练单音素模型" class="headerlink" title="2. 训练单音素模型"></a>2. 训练单音素模型</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">steps/train_mono.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/mono || exit 1;</span><br></pre></td></tr></table></figure>
<p>参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/82380716">kaldi-GMM-HMM pipeline</a>，上面的shell脚本主要是对齐音素和每一帧音频的。<a target="_blank" rel="noopener" href="https://blog.csdn.net/DanyHgc/article/details/75247158">Kaldi 入门train_mono.sh详解</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/DuishengChen/article/details/52575926">kaldi学习笔记 – 训练单音素（monophone）模型脚本 – steps&#x2F;train_mono.sh</a>都有讲一些。<br>对流程讲得最好的是：<br>mkgraph 需要 lang_test 下的 L.fst G.fst phones.txt, words.txt , phones&#x2F;silence.csl , phones&#x2F;<a href="https://link.zhihu.com/?target=http://disambig.int">http://disambig.int</a></p>
<p>以及 exp&#x2F;tri 下的 tree, final.mdl</p>
<blockquote>
<p>在训练的job并行训练过程中，训练数据的各个子集合是分散到不同的处理器去进行训练，然后每轮迭代后会进行合并。<br>下面就讲一下训练的过程：<br>1.首先是初始化GMM，使用的脚本是&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-init-mono，输出是0.mdl和tree文件；<br>2.compile training graphs,使用的脚本是&#x2F;kaldi-trunk&#x2F;source&#x2F;bin&#x2F;compile-training-graphs，输入是tree,0.mdl和L.fst,输出是fits.JOB.gz，其是在训练过程中构建graph的过程；<br>3.接下来是一个对齐的操作，kaldi-trunk&#x2F;source&#x2F;bin&#x2F;align-equal-compiled；<br>4.然后是基于GMM的声学模型进行最大似然估计得过程，脚本为&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-est；<br>5.然后进行迭代循环中进行操作，如果本步骤到了对齐的步骤，则调用脚本kaldi-kaldi&#x2F;src&#x2F;gmmbin&#x2F;gmm-align-compiled；<br>6.重新估计GMM，累计状态，用脚本&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-acc-states-ali；调用新生成的参数(高斯数)重新估计GMM，调用脚本&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-est；<br>7.对分散在不同处理器上的结果进行合并，生成.mdl结果，调用脚本gmm-acc-sum；<br>8.增加高斯数，如果没有超过设定的迭代次数，则跳转到步骤5重新进行训练<br>最后生成的.mdl即为声学模型文件<br>在离线识别阶段，即可以调用utils&#x2F;mkgraph.sh；来对刚刚生成的声学文件进行构图<br>之后解码，得到离线测试的识别率。</p>
</blockquote>
<h4 id="3-Monophone-decoding-单音素解码"><a href="#3-Monophone-decoding-单音素解码" class="headerlink" title="3. (Monophone decoding) 单音素解码"></a>3. (Monophone decoding) 单音素解码</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">utils/mkgraph.sh data/lang_test exp/mono exp/mono/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/mono/graph data/dev exp/mono/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/mono/graph data/test exp/mono/decode_test</span><br></pre></td></tr></table></figure>
<p><code>mkgraph.sh</code>将L_disambig.fst 和 G.fst 复合生成LG.fst。中间经历了我看不懂的处理。最终生成用于解码的 HCLG.fst。</p>
<h4 id="看不懂的部分"><a href="#看不懂的部分" class="headerlink" title="看不懂的部分"></a>看不懂的部分</h4><p>后面就已经看不懂了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"># Get alignments from monophone system.</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/mono exp/mono_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># train tri1 [first triphone pass]</span><br><span class="line">steps/train_deltas.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/mono_ali exp/tri1 || exit 1;</span><br><span class="line"></span><br><span class="line"># decode tri1</span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri1 exp/tri1/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri1/graph data/dev exp/tri1/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri1/graph data/test exp/tri1/decode_test</span><br><span class="line"></span><br><span class="line"># align tri1</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri1 exp/tri1_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># train tri2 [delta+delta-deltas]</span><br><span class="line">steps/train_deltas.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/tri1_ali exp/tri2 || exit 1;</span><br><span class="line"></span><br><span class="line"># decode tri2</span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri2 exp/tri2/graph</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri2/graph data/dev exp/tri2/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri2/graph data/test exp/tri2/decode_test</span><br><span class="line"></span><br><span class="line"># train and decode tri2b [LDA+MLLT]</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri2 exp/tri2_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># Train tri3a, which is LDA+MLLT,</span><br><span class="line">steps/train_lda_mllt.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/tri2_ali exp/tri3a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri3a exp/tri3a/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri3a/graph data/dev exp/tri3a/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri3a/graph data/test exp/tri3a/decode_test</span><br><span class="line"></span><br><span class="line"># From now, we start building a more serious system (with SAT), and we&#x27;ll</span><br><span class="line"># do the alignment with fMLLR.</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri3a exp/tri3a_ali || exit 1;</span><br><span class="line"></span><br><span class="line">steps/train_sat.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line">  2500 20000 data/train data/lang exp/tri3a_ali exp/tri4a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri4a exp/tri4a/graph</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri4a/graph data/dev exp/tri4a/decode_dev</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri4a/graph data/test exp/tri4a/decode_test</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh  --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri4a exp/tri4a_ali</span><br><span class="line"></span><br><span class="line"># Building a larger SAT system.</span><br><span class="line"></span><br><span class="line">steps/train_sat.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line">  3500 100000 data/train data/lang exp/tri4a_ali exp/tri5a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri5a exp/tri5a/graph || exit 1;</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">   exp/tri5a/graph data/dev exp/tri5a/decode_dev || exit 1;</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">   exp/tri5a/graph data/test exp/tri5a/decode_test || exit 1;</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri5a exp/tri5a_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># nnet3</span><br><span class="line">local/nnet3/run_tdnn.sh</span><br><span class="line"></span><br><span class="line"># chain</span><br><span class="line">local/chain/run_tdnn.sh</span><br></pre></td></tr></table></figure>

<h3 id="获取结果"><a href="#获取结果" class="headerlink" title="获取结果"></a>获取结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># getting results (see RESULTS file)</span><br><span class="line">for x in exp/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br><span class="line">for x in exp/*/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure>
<p>和上一篇文章一样的步骤。<br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/09deba57f339">Kaldi入门：yesno项目</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/" data-id="clnhnlj2t0014zox142lo7eb4" data-title="学习Kaldi：中文Aishell项目（上）" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ASR/" rel="tag">ASR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaldi/" rel="tag">Kaldi</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-使用Python开发桌面应用的一个体验" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/23/%E4%BD%BF%E7%94%A8Python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/" class="article-date">
  <time class="dt-published" datetime="2020-11-23T11:36:00.000Z" itemprop="datePublished">2020-11-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/11/23/%E4%BD%BF%E7%94%A8Python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/">使用Python开发桌面应用的一个体验</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>我的主力编程语言现在是Python，平时也会使用Python写一些小脚本做文件处理（更简单一些的操作会直接用Shell命令）。基本不会接触到GUI界面的编写。但是呢，对于我而言命令行是可行的方案，但是如果要把代码交给没有编程基础的人，并且没有相关的开发环境时。就需要GUI和打包技术了。最近就遇到一个情况需要开发一个类似图片直方图均衡的功能给和课题组合作的医生使用，工作的电脑是离线的，医生没有编程基础。</p>
<p>要求条件：</p>
<ol>
<li><p>使用Python，快捷开发；</p>
</li>
<li><p>GUI；</p>
</li>
<li><p>独立的EXE可执行文件。</p>
</li>
</ol>
<p>技术栈：</p>
<ol>
<li><p>Numpy，用于对像素数组进行映射；</p>
</li>
<li><p>Pillow，图像库，底层调用numpy；</p>
</li>
<li><p>TkinterDND2使用Python内置的Tkinter的改进版，支持基础的code based UI和文件拖拽功能。使用conda安装。</p>
</li>
</ol>
<p>我的开发环境是OS X，幸好之前一个老师分配的Windows虚拟机还能用。Python环境3.7.3。</p>
<h2 id="第一版"><a href="#第一版" class="headerlink" title="第一版"></a>第一版</h2><p><img src="/images/1240.png" alt="image.png"> </p>
<p>支持选取图片文件夹，递归查找其中的jpg文件并处理。</p>
<h3 id="文件夹选取功能"><a href="#文件夹选取功能" class="headerlink" title="文件夹选取功能"></a>文件夹选取功能</h3><h3 id=""><a href="#" class="headerlink" title=""></a><strong><img src="/images/1241.png" alt="image.png"></strong></h3><h3 id="图片处理函数"><a href="#图片处理函数" class="headerlink" title="图片处理函数"></a>图片处理函数</h3><h3 id="-1"><a href="#-1" class="headerlink" title=""></a><strong><img src="/images/1242.png" alt="image.png"></strong></h3><p>简单的对图片像素映射到0-255的范围。能够使得标本图片更容易标注。</p>
<h3 id="恢复函数"><a href="#恢复函数" class="headerlink" title="恢复函数"></a>恢复函数</h3><h3 id="-2"><a href="#-2" class="headerlink" title=""></a><strong><img src="/images/1243.png" alt="image.png"></strong></h3><p>相当于图片处理函数的逆操作，在图片处理的时候保存了每一张图片的处理参数。</p>
<h3 id="性能分析："><a href="#性能分析：" class="headerlink" title="性能分析："></a>性能分析：</h3><h3 id="-3"><a href="#-3" class="headerlink" title=""></a><strong><img src="/images/1244.png" alt="image.png"></strong></h3><p>因为一个标本采集的图片有接近2000张，测试时预估大约需要8分钟才能完成一个标本的图片优化。而费</p>
<p>使用cProfile进行性能分析，61张图片要18秒多。平均一秒3张图片。主要的时间消耗是在转换成numpy矩阵、保存图片和图片处理函数。基本是不能够再优化的。那么就要从数据量方面考虑，是否每一张图片都需要优化并标注？其实不是的，每一个标本只需要选取最多10张进行标注，那么由医生选取并且拖放到指定界面会更快捷。</p>
<h2 id="第二版"><a href="#第二版" class="headerlink" title="第二版"></a>第二版</h2><h2 id="-4"><a href="#-4" class="headerlink" title=""></a><strong><img src="/images/1245.png" alt="image.png"></strong></h2><p>第二版添加了拖放功能并且把文件夹选取的功能去掉了。可以拖放多个文件，并且会筛选处理其中的jpg文件。</p>
<p>PS: 连标题都懒得改。。</p>
<h2 id="pyinstaller打包"><a href="#pyinstaller打包" class="headerlink" title="pyinstaller打包"></a>pyinstaller打包</h2><p>使用pip 安装pyinstaller打包，pyinstaller是系统依赖的，在什么系统打包，在什么系统使用。坑很多。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>使用pyinstaller遇到几个bug。six，warm</p>
<p>打包太大了。有500MB。代码量180行。</p>
<p>加了Frame之后文件夹输入框就不更新了。可能的原因是pack和grid在frame和widge之间混用。或者混用Tkinter和TkinterDnD2。因为文件夹选取的方案被替换掉了。所以这个bug不再存在。</p>
<p>conda环境安装耗时较久。</p>
<p>还是java香。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/11/23/%E4%BD%BF%E7%94%A8Python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/" data-id="clnhnlj2p000zzox16bmk4ybq" data-title="使用Python开发桌面应用的一个体验" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-以Notion为基础的自我管理体系" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/23/%E4%BB%A5Notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/" class="article-date">
  <time class="dt-published" datetime="2020-11-23T11:35:15.000Z" itemprop="datePublished">2020-11-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/11/23/%E4%BB%A5Notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/">以Notion为基础的自我管理体系</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>我常用<a target="_blank" rel="noopener" href="https://www.notion.so/imchenmin/Todoist-7dc5a0cd012e41a6b2cfef696e869a00">Todoist</a> 管理自己的任务，用<a target="_blank" rel="noopener" href="https://www.notion.so/imchenmin/175adc9e20194d2b97062999b44255bb">印象笔记</a>存放感兴趣的文本和自己觉得需要保存的文本。</p>
<p>后来因为Notion的数据库特质吸引到我。所以整合之前的项目管理、任务管理和笔记文本管理在Notion之中。</p>
<p>Notion的缺点在于过于自由，需要加一个框架来使之符合项目管理、任务管理、文本笔记管理的功能。</p>
<p>使用前后端分离的方式，将整个Notion空间分为View和Model，用一些自定义的数据库来组织不同类型的数据，位于根目录Resources之下。</p>
<h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><p>Resource</p>
<ul>
<li><p>Notes（笔记）</p>
<p><img src="/images/1260.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-021.01.51.png"> </p>
</li>
<li><p>Book（书籍）</p>
<p><img src="/images/1261.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-025.05.59.png"> </p>
</li>
<li><p>Video（想看的，看过的视频）</p>
<p><img src="/images/1262.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-025.08.20.png"> </p>
</li>
<li><p>People（人脉）</p>
</li>
<li><p>Thing（事情，分为Task和Calendar）</p>
<p><img src="/images/1263.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-025.09.09.png"> </p>
</li>
<li><p>Tag（标签）</p>
<p><img src="/images/1264.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-026.28.14.png"> </p>
</li>
<li><p>Subscription（订阅服务）</p>
<p><img src="/images/1265.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-026.29.41.png"> </p>
</li>
<li><p>Project（基于项目的自我管理），与Things、note联系。</p>
<p><img src="/images/1266.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-029.09.57.png"></p>
</li>
</ul>
<h2 id="Dashboard"><a href="#Dashboard" class="headerlink" title="Dashboard"></a>Dashboard</h2><p>主要通过Dashboard这一个页面来管理自己当天的任务、任务收件箱和笔记。</p>
<p><img src="/images/1267.png" alt="Notion%2059beed18f91a433abd3b3c79042c9eb7/2020-07-026.35.02.png"> </p>
<h2 id="善用过滤器和视图类型"><a href="#善用过滤器和视图类型" class="headerlink" title="善用过滤器和视图类型"></a>善用过滤器和视图类型</h2><p>数据库可以自选多种视图类型，如列表，日历，卡片，表格等。并且可以使用过滤功能。但是一个视图只能有一个过滤器。通过复制视图可以达到快速创建相同类型的视图和不同的过滤功能。</p>
<h2 id="适用情况与不适用情况"><a href="#适用情况与不适用情况" class="headerlink" title="适用情况与不适用情况"></a>适用情况与不适用情况</h2><p>Notion到目前为止都不能避免的两个大山：</p>
<ol>
<li><p>GFW</p>
</li>
<li><p>Web App</p>
</li>
</ol>
<p>第一点导致很难让其他人访问，导致作为团队共享或者公开访问需要较大的门槛。</p>
<p>Notion到现在为止都是以HTML，CSS，JS为基础的。所谓的客户端都是网页，并没有多强的离线功能，更别提下载某一个页面。与系统的整合很差。没有单独的页面快捷入口，比起Todoist和印象笔记存在较大的稳定问题。</p>
<p>如果网络环境不好，要做好不能够随时访问重要信息的准备！</p>
<p>所以我会有一个Tag叫Save to Evernote来手动将重要的信息保存到印象笔记并且离线下来，遇到任务也会先放到Todoist中，等能连上网的时候再同步。</p>
<p>原文链接：<a target="_blank" rel="noopener" href="https://www.notion.so/imchenmin/Notion-d7b4ef1b46aa4ef7b73dc3fb25d5a2d1">https://www.notion.so/imchenmin/Notion-d7b4ef1b46aa4ef7b73dc3fb25d5a2d1</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/11/23/%E4%BB%A5Notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/" data-id="clnhnlj2x001azox1ewpm60w0" data-title="以Notion为基础的自我管理体系" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA/" rel="tag">个人</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86/" rel="tag">知识管理</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Ubuntu-18-04静态IP设置和遇到的虚拟机网卡问题" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/23/Ubuntu-18-04%E9%9D%99%E6%80%81IP%E8%AE%BE%E7%BD%AE%E5%92%8C%E9%81%87%E5%88%B0%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E5%8D%A1%E9%97%AE%E9%A2%98/" class="article-date">
  <time class="dt-published" datetime="2020-11-23T11:34:17.000Z" itemprop="datePublished">2020-11-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/11/23/Ubuntu-18-04%E9%9D%99%E6%80%81IP%E8%AE%BE%E7%BD%AE%E5%92%8C%E9%81%87%E5%88%B0%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E5%8D%A1%E9%97%AE%E9%A2%98/">Ubuntu 18.04静态IP设置和遇到的虚拟机网卡问题</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>帮同学的实验室配置静态IP，将其中的流程和关键记录下来。</p>
<p>校园网内使用DHCP来分配IP地址，有效期为2天，如果两天之内设备未续租，IP地址会被收回。</p>
<p>实验室的服务器需要远程登陆，需要一个静态IP来保证服务器的可访问性。</p>
<p>在申请了几个静态IP之后，会获得一组数据。1) 172.xxx.xxx.xxx、2) 255.255.255.0、3) 172.xxx.xxx.254、4) vlanxx。其中1）是静态IP的地址，2）是子网掩码，也可以用24表示。3）网关地址，4）交换机的vlan接口，由交换机管理员配置。</p>
<p>学校中由网络中心运营管理交换机，需要先联系工程师在网关中添加vlanxx接口，并且把服务器的所有MAC地址绑定静态IP地址组。</p>
<p>服务器的操作系统和版本是Ubuntu 18.04 server。网络管理使用netplan。之前同学装了gnome-shell。我先尝试使用简易桌面自带的网络管理程序，ifconfig -a发现对网卡配置不起作用。</p>
<p>直接修改netplan程序位于\etc\netplan\01-netcfg.yaml。</p>
<p>当时该文件基本的结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: networkd</span><br><span class="line">  ethernets:</span><br><span class="line">    eno1:</span><br><span class="line">      dhcp4: true</span><br><span class="line">  bridges:</span><br><span class="line">    vir0br:</span><br><span class="line">      interfaces: [eno1]</span><br><span class="line">      dhcp4: true</span><br></pre></td></tr></table></figure>
<p>需要注意的就是eno1和vir0br。其中dhcp4代表着是否使用ipv4版本的dhcp地址分配。</p>
<p>vir0br是<a target="_blank" rel="noopener" href="https://virt-manager.org/">https://virt-manager.org/</a>虚拟机管理器NAT模式下的网桥接口。服务器中通过virt-manager运行着windows 系统。</p>
<p>配置静态ip需要修改eno1的配置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">eno1:</span><br><span class="line">  dhcp4: no</span><br><span class="line">  addresses: [172.xxx.xxx.xxx/24]</span><br><span class="line">  gateway4: 172.xxx.xxx.254</span><br><span class="line">  nameservers:</span><br><span class="line">    addresses: [8.8.8.8, 8.8.4.4]</span><br></pre></td></tr></table></figure>
<p>然后netplan apply。接着ifconfig -a 查看网卡ip是否更改，如果没有更改，不用着急。很可能是配置文件的问题。而不是需要重启或者sudo service networking restart重启网卡。</p>
<p>需要注意的是这里有一个bridge。bridge是一个虚拟网络设备，具有网络设备的特征，可以配置IP，MAC地址等。bridge不分接入进来的设备是虚拟的还是物理的，当eno1加入vir0br之后，从外面网络收到的数据包将无条件的转发给vir0br，自己变成一根网线。先用brctl show查看网桥状态然后.ifconfig &lt;网桥名&gt; down, brctl delbr &lt;网桥名&gt;删除网桥，将01-netcf.yaml中的bridge 部分删掉。（但是会造成虚拟机网络异常）。 重新netplan apply，完成静态IP的配置。</p>
<p>对于windows虚拟机的网络配置还在检索学习中。网上较少Linux寄主机，Windows虚拟机的配置情况。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/11/23/Ubuntu-18-04%E9%9D%99%E6%80%81IP%E8%AE%BE%E7%BD%AE%E5%92%8C%E9%81%87%E5%88%B0%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E5%8D%A1%E9%97%AE%E9%A2%98/" data-id="clnhnlj1x000ozox1elj35avu" data-title="Ubuntu 18.04静态IP设置和遇到的虚拟机网卡问题" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-OpenCV和numpy笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/22/OpenCV%E5%92%8Cnumpy%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2020-11-22T12:33:53.000Z" itemprop="datePublished">2020-11-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/11/22/OpenCV%E5%92%8Cnumpy%E7%AC%94%E8%AE%B0/">OpenCV和numpy笔记</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>使用K-means做视频图像分割的作业的时候，遇到一个问题值得记录。</p>
<p>该代码的功能是使用K-means做图像分割并保存图像与视频。</p>
<p>遇到的问题是kmean之后得到的是每一个像素点的分类标签，需要将这些标签可视化成为分割(Segmentation)的结果视频。一开始没有直接找到相关的函数，搜索查询后给的建议都是使用<code>matlibplot</code>的<code>plt.imshow()</code>函数来实现，但是我不想要每次保存成为图片再转成视频，考虑到opencv-python的底层使用<code>numpy.array</code>来表述图像的。一个BGR图像相当于一个3维uint8数组（w,h,c)。要做的就是生成一个标签到像素的映射关系。这里我用的是<code>matplotlib.cm</code> color map 功能。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(0.0, 1.0, 10)</span><br><span class="line">rgb = cm.get_cmap(plt.get_cmap(&#x27;Set1&#x27;))(x)[np.newaxis, :, :3][0]</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from numpy.matlib import repmat</span><br><span class="line">from sklearn.preprocessing import normalize</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib import cm</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">import cv2</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">n_cl=5</span><br><span class="line"></span><br><span class="line">videoCapture = cv2.VideoCapture(&#x27;road_video.mov&#x27;)</span><br><span class="line">fps = videoCapture.get(cv2.CAP_PROP_FPS)</span><br><span class="line">size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),</span><br><span class="line">        int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))</span><br><span class="line">videoWriter = cv2.VideoWriter(&#x27;output.mp4&#x27;, cv2.VideoWriter_fourcc(*&#x27;mp4v&#x27;), (fps/10), size)</span><br><span class="line"></span><br><span class="line">def kmeans(data, n_cl, verbose=True):</span><br><span class="line">    n_samples, dim = data.shape</span><br><span class="line">    centers = data[np.random.choice(range(n_samples), size=n_cl)]</span><br><span class="line">    old_labels = np.zeros(shape=n_cl)</span><br><span class="line">    while True:</span><br><span class="line">        distances = np.zeros((n_samples, n_cl))</span><br><span class="line">        for cluster_idx, cluster in enumerate(centers):</span><br><span class="line">            distances[:, cluster_idx] = np.sum(np.square(data - repmat(cluster, n_samples, 1)), axis=1)</span><br><span class="line">        new_labels = np.argmin(distances, axis=1)</span><br><span class="line">        for l in range(0, n_cl):</span><br><span class="line">            centers[l] = np.mean(data[new_labels==l], axis=0)</span><br><span class="line">        if verbose:</span><br><span class="line">            fig, ax = plt.subplots()</span><br><span class="line">            ax.scatter(data[:, 0], data[:, 1], cluster=new_labels, s=40)</span><br><span class="line">            ax.plot(centers[:, 0], centers[:, 1], &#x27;r*&#x27;, markersize=20)</span><br><span class="line">            plt.waitforbuttonpress()</span><br><span class="line">            plt.close()</span><br><span class="line">        if np.array_equal(new_labels, old_labels):</span><br><span class="line">            break</span><br><span class="line">        old_labels = new_labels</span><br><span class="line">    return new_labels</span><br><span class="line"></span><br><span class="line">count = 0</span><br><span class="line">x = np.linspace(0.0, 1.0, 10)</span><br><span class="line">rgb = cm.get_cmap(plt.get_cmap(&#x27;Set1&#x27;))(x)[np.newaxis, :, :3][0]</span><br><span class="line"></span><br><span class="line">while True:</span><br><span class="line">    print(count)</span><br><span class="line">    count += 1</span><br><span class="line">#   load the frame</span><br><span class="line">    success, frame = videoCapture.read()</span><br><span class="line">    if not success:</span><br><span class="line">        break</span><br><span class="line">    img = np.float32(frame)</span><br><span class="line">    h,w,c = img.shape</span><br><span class="line">    # print(h,w,c)</span><br><span class="line">#   add coordinates</span><br><span class="line">    row_indexes = np.arange(0, h)</span><br><span class="line">    col_indexes = np.arange(0, w)</span><br><span class="line">    coordinates = np.zeros(shape=(h,w,2))</span><br><span class="line">    coordinates[..., 0] = normalize(repmat(row_indexes, w, 1).T)</span><br><span class="line">    coordinates[..., 1] = normalize(repmat(col_indexes, h, 1))</span><br><span class="line">    data = np.concatenate((img, coordinates), axis=-1)</span><br><span class="line">    data = np.reshape(data, newshape=(w *h, 5))</span><br><span class="line">    labels = kmeans(data, n_cl=n_cl, verbose=False)</span><br><span class="line"></span><br><span class="line">    print(&#x27;after&#x27;)</span><br><span class="line">    labels = labels.flatten()</span><br><span class="line">    segmented_image = rgb[labels.flatten()]</span><br><span class="line">    # print(segmented_image)</span><br><span class="line">    segmented_image = segmented_image.reshape(img.shape)</span><br><span class="line">    plt.imshow(segmented_image)</span><br><span class="line">    # # plt.imshow(np.reshape(labels, (h, w)), cmap=&quot;hsv&quot;)</span><br><span class="line">    plt.savefig(&quot;lab9/&quot;+str(count-1))</span><br><span class="line">    segmented_image = segmented_image *255</span><br><span class="line">    segmented_image = segmented_image.astype(&#x27;uint8&#x27;)</span><br><span class="line">    videoWriter.write(segmented_image)</span><br><span class="line"></span><br><span class="line">videoWriter.release()</span><br><span class="line">videoCapture.release()</span><br></pre></td></tr></table></figure>

<h2 id="参考网页"><a href="#参考网页" class="headerlink" title="参考网页"></a>参考网页</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/llh_1178/article/details/77833447">https://blog.csdn.net/llh_1178/article/details/77833447</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.opencv.org/3.4/d4/dba/classcv_1_1viz_1_1Color.html">https://docs.opencv.org/3.4/d4/dba/classcv_1_1viz_1_1Color.html</a></p>
<p><a target="_blank" rel="noopener" href="https://realpython.com/python-opencv-color-spaces/">https://realpython.com/python-opencv-color-spaces/</a></p>
<p><a target="_blank" rel="noopener" href="https://www.thepythoncode.com/article/kmeans-for-image-segmentation-opencv-python">https://www.thepythoncode.com/article/kmeans-for-image-segmentation-opencv-python</a></p>
<p><a target="_blank" rel="noopener" href="https://pvss.github.io/Opencv+Python.html">https://pvss.github.io/Opencv+Python.html</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/9280653/writing-numpy-arrays-using-cv2-videowriter">https://stackoverflow.com/questions/9280653/writing-numpy-arrays-using-cv2-videowriter</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/11/22/OpenCV%E5%92%8Cnumpy%E7%AC%94%E8%AE%B0/" data-id="clnhnlj1r000ezox1fe0448md" data-title="OpenCV和numpy笔记" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Numpy/" rel="tag">Numpy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OpenCV/" rel="tag">OpenCV</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/" rel="tag">编程记录</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-新服务器迁移postgres数据库" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/21/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/" class="article-date">
  <time class="dt-published" datetime="2020-11-21T01:39:33.000Z" itemprop="datePublished">2020-11-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/11/21/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/">新服务器迁移postgres数据库</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>课题组要部署一个云服务，之前用的是我个人申请的学生版服务器，价格优惠。快到期需要续费，但是优惠版的服务器不能够继续以优惠价格续费，正常的价格是一千多每年。所以我决定新申请一个优惠版服务器，然后迁移Postgres数据库和部署的web server。</p>
<p>基本步骤是购买新服务器（Ubuntu18.04版本），密码重设，为了方便登录也可以设置ssh免密码登录。</p>
<h2 id="安装配置Postgres"><a href="#安装配置Postgres" class="headerlink" title="安装配置Postgres"></a>安装配置Postgres</h2><p>我觉得Postgres比MySQL好的一点在于其开源。且能实现数据库的基本功能。</p>
<h3 id="服务器安装Postgres"><a href="#服务器安装Postgres" class="headerlink" title="服务器安装Postgres"></a>服务器安装Postgres</h3><p><code>sudo apt-get install postgresql postgresql-client </code></p>
<p>可以在本机安装一个postgres-client，免得在两个服务器之间来回登录。</p>
<h3 id="配置postgres数据库账号和远程连接"><a href="#配置postgres数据库账号和远程连接" class="headerlink" title="配置postgres数据库账号和远程连接"></a>配置postgres数据库账号和远程连接</h3><p>登录新服务器，设置linux中的postgres用户密码</p>
<p><code>sudo passwd postgres</code>或者<code>sudo -i -u postgres</code>，免密码登录。</p>
<p>设置postgres 中postgres用户密码(以postgres用户登录)</p>
<p><code>psql</code>进入数据库clinet软件</p>
<p><code>postgres \password</code>设置数据库管理员postgres的密码</p>
<h3 id="远程连接设置"><a href="#远程连接设置" class="headerlink" title="远程连接设置"></a>远程连接设置</h3><p>修改Postgres远程连接允许 </p>
<p><code>sudo vim /etc/postgres/10/main/postgres.conf</code>， </p>
<p>修改<code>listen_addresses</code>那一行为<code>listen_addresses = &#39;*&#39;</code>（有的公司要求不允许数据库开放外网访问，请谨慎该选项）。</p>
<p>修改远程登录选项</p>
<p><code>vim  /etc/postgres/10/main/pg_dba.conf</code></p>
<p>添加新行</p>
<p><code> host  all  all 0.0.0.0/0 md5</code> (不要使用trust，除非你想任何人能够访问你的数据库内容)</p>
<p>重启服务以应用刚刚的修改</p>
<p><code>sudo service postgresql restart</code></p>
<p><a target="_blank" rel="noopener" href="http://lazybios.com/2016/11/how-to-make-postgreSQL-can-be-accessed-from-remote-client/">参考</a></p>
<h2 id="数据库迁移"><a href="#数据库迁移" class="headerlink" title="数据库迁移"></a>数据库迁移</h2><p>Postgres 提供导出数据库数据和结构的程序。有两种方法，一种是在本机安装psql程序，新旧服务器都进行上面的远程连接设置，然后本机连接源服务器数据库dump备份文件，然后本机连接目标服务器数据库导入数据；另外一种是登录源服务器dump备份文件，再导出到目标服务器，在目标服务器执行导入操作。我使用的是比较麻烦的第二种。</p>
<h3 id="备份数据库"><a href="#备份数据库" class="headerlink" title="备份数据库"></a>备份数据库</h3><p><code>pg_dump -h (ip or localhost) -U postgres databasename &gt; databasename.bak</code></p>
<p>我是在服务器本地进行的操作，所以可以使用localhost。</p>
<h3 id="恢复数据库"><a href="#恢复数据库" class="headerlink" title="恢复数据库"></a>恢复数据库</h3><p>恢复数据库指令不会创建新的数据库，所以需要先行在新的数据库中创建数据库 <code>create database databasename;</code></p>
<p>然后执行<code>psql -h localhost -U postgres -d databasename &lt; databasename.bak</code>恢复数据库。</p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844904002409201671">参考</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/11/21/%E6%96%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BBpostgres%E6%95%B0%E6%8D%AE%E5%BA%93/" data-id="clnhnlj2y001bzox183nx9cn2" data-title="新服务器迁移postgres数据库" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Postgres/" rel="tag">Postgres</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BF%90%E7%BB%B4/" rel="tag">运维</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Kaldi入门-一-yesno项目" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/05/01/Kaldi%E5%85%A5%E9%97%A8-%E4%B8%80-yesno%E9%A1%B9%E7%9B%AE/" class="article-date">
  <time class="dt-published" datetime="2020-05-01T09:37:05.000Z" itemprop="datePublished">2020-05-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/05/01/Kaldi%E5%85%A5%E9%97%A8-%E4%B8%80-yesno%E9%A1%B9%E7%9B%AE/">Kaldi入门(一):yesno项目</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>这个学期选了一门自然语言处理课，结果这门课主要的研究课题是自动语音识别（ASR）。既然入了这个坑。就先好好了解一下如何做ASR吧。<br>老师Tom Ko要求使用Kaldi这个工具来做ASR。课上到一半才知道Kaldi中有几千行的脚本代码是老师提交的。好吧，脚本好难的。<br>为了入门Kaldi，课程的第5次Lab是一个mini projec: yesno</p>
<p>首先要下载并编译Kaldi，安装的过程不是我的学习重点，可以先参考<a href="%5Bhttps://blog.csdn.net/snowdroptulip/article/details/78896915%5D(https://blog.csdn.net/snowdroptulip/article/details/78896915)">Kaldi的下载安装与编译</a>，在漫长的编译过程之后假设已经安装好了Kaldi。</p>
<h2 id="项目目录结构"><a href="#项目目录结构" class="headerlink" title="项目目录结构"></a>项目目录结构</h2><p>yesno项目的脚本和README都在<code>kaldi/egs/yesno</code>之下。<br>README.txt文件中包含数据集描述：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">The &quot;yesno&quot; corpus is a very small dataset of recordings of one individual</span><br><span class="line">saying yes or no multiple times per recording, in Hebrew.  It is available from</span><br><span class="line">http://www.openslr.org/1.</span><br><span class="line">It is mainly included here as an easy way to test out the Kaldi scripts.</span><br><span class="line"></span><br><span class="line">The test set is perfectly recognized at the monophone stage, so the dataset is</span><br><span class="line">not exactly challenging.</span><br><span class="line"></span><br><span class="line">The scripts are in s5/.</span><br></pre></td></tr></table></figure>
<p>数据脚本路径： kaldi&#x2F;egs&#x2F;yesno&#x2F;s5。在下面执行的很多操作都可以直接调用已经写好的脚本来执行，之所以深入到具体的流程中是为了加强对ASR流程的理解。</p>
<h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p>第一步是从网络上下载数据集文件<code>waves_yesno.tar.gz</code>到s5&#x2F;路径下并解压。<br>原始的数据是60个.wav文件。文件名是八个用下划线分隔的01组合。需要将音频数据转化成kaldi能够处理的格式。</p>
<h2 id="转换成Kaldi能处理的格式"><a href="#转换成Kaldi能处理的格式" class="headerlink" title="转换成Kaldi能处理的格式"></a>转换成Kaldi能处理的格式</h2><p>下载完数据集后，将数据集划分为31个训练，30个测试（数量大致相当）。在s5&#x2F;下创建data文件夹，把划分好的音频文件放入train_yesno和test_yesno。</p>
<p>Kaldi使用以下几个文件来表示数据：</p>
<ol>
<li><p>Text<br>音频的文本记录。每一个音频文件一行。格式为<code>&lt;utt_id&gt; &lt;transcript&gt;</code>。<utt_id>为音频的id，一般用不带扩展名的文件名表示。utt_id在wav.scp文件中与具体的文件映射。<transcript>是音频对应的文字。</p>
</li>
<li><p>wav.scp<br>将文件映射到唯一的utt_id。<br>格式为<code>&lt;utt_id&gt; &lt;path or command to get wave file&gt;</code><br>第二个参数既可以是对应utt_id的音频文件路径，也可以是能够获得音频文件的指令。</p>
</li>
<li><p>utt2spk<br>对于每一个音频文件，标记是哪一个人发音的。因为yesno数据集中只有一个发音者，用global来表示所有的utt_id<br>文件内每一行的格式为<code>&lt;utt_id&gt; &lt;speaker_id&gt;</code></p>
</li>
<li><p>spk2utt<br>和3反过来。文件内每一行对应一个发音者，第一个是speaker的id，后面用空格分隔开60个utt_id。格式为<code>&lt;speaker_id&gt; &lt;utt_id1&gt; &lt;utt_id2&gt; ...</code></p>
</li>
</ol>
<p>本步骤可直接调用脚本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> kaldi/egs/yesno/s5</span><br><span class="line"><span class="built_in">local</span>/prepare_data.sh waves_yesno</span><br></pre></td></tr></table></figure>
<p>读了一下prepare_data.sh的脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p data/local</span><br><span class="line"><span class="built_in">local</span>=`<span class="built_in">pwd</span>`/local</span><br><span class="line">scripts=`<span class="built_in">pwd</span>`/scripts</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:`<span class="built_in">pwd</span>`/../../../tools/irstlm/bin</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Preparing train and test data&quot;</span></span><br><span class="line"></span><br><span class="line">train_base_name=train_yesno</span><br><span class="line">test_base_name=test_yesno</span><br><span class="line">waves_dir=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">ls</span> -1 <span class="variable">$waves_dir</span> &gt; data/local/waves_all.list</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> data/local</span><br><span class="line"></span><br><span class="line">../../local/create_yesno_waves_test_train.pl waves_all.list waves.test waves.train</span><br><span class="line"></span><br><span class="line">../../local/create_yesno_wav_scp.pl <span class="variable">$&#123;waves_dir&#125;</span> waves.test &gt; <span class="variable">$&#123;test_base_name&#125;</span>_wav.scp</span><br><span class="line"></span><br><span class="line">../../local/create_yesno_wav_scp.pl <span class="variable">$&#123;waves_dir&#125;</span> waves.train &gt; <span class="variable">$&#123;train_base_name&#125;</span>_wav.scp</span><br><span class="line"></span><br><span class="line">../../local/create_yesno_txt.pl waves.test &gt; <span class="variable">$&#123;test_base_name&#125;</span>.txt</span><br><span class="line"></span><br><span class="line">../../local/create_yesno_txt.pl waves.train &gt; <span class="variable">$&#123;train_base_name&#125;</span>.txt</span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> ../../input/task.arpabo lm_tg.arpa</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ../..</span><br><span class="line"></span><br><span class="line"><span class="comment"># This stage was copied from WSJ example</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> train_yesno test_yesno; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">mkdir</span> -p data/<span class="variable">$x</span></span><br><span class="line">  <span class="built_in">cp</span> data/local/<span class="variable">$&#123;x&#125;</span>_wav.scp data/<span class="variable">$x</span>/wav.scp</span><br><span class="line">  <span class="built_in">cp</span> data/local/<span class="variable">$x</span>.txt data/<span class="variable">$x</span>/text</span><br><span class="line">  <span class="built_in">cat</span> data/<span class="variable">$x</span>/text | awk <span class="string">&#x27;&#123;printf(&quot;%s global\n&quot;, $1);&#125;&#x27;</span> &gt; data/<span class="variable">$x</span>/utt2spk</span><br><span class="line">  utils/utt2spk_to_spk2utt.pl &lt;data/<span class="variable">$x</span>/utt2spk &gt;data/<span class="variable">$x</span>/spk2utt</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h2 id="建立词典"><a href="#建立词典" class="headerlink" title="建立词典"></a>建立词典</h2><p>对于当前项目，我们只有两个词 Ken(yes) 和 Lo（no)。但是在真实的语言中，词的数量不可能这么少，并且还有停顿和环境噪声。kaldi将这些非语言的声音称作slience（SIL）。<br>加上SIL一共需要三个词来表示当前这个yesno语言模型。</p>
<p>调用脚本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">local</span>/prepare_dict.sh</span><br></pre></td></tr></table></figure>
<p>将会在s5&#x2F;data&#x2F;local&#x2F;dict中看到新生成的5个文件。</p>
<ol>
<li>lexicon.txt<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;SIL&gt; SIL</span><br><span class="line">YES Y</span><br><span class="line">NO N</span><br></pre></td></tr></table></figure></li>
<li>lexicon_words.txt<br>比1少第一行</li>
<li>nonsilence_phones.txt<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y</span><br><span class="line">N</span><br></pre></td></tr></table></figure></li>
<li>silence_phones.txt<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SIL</span><br></pre></td></tr></table></figure></li>
<li>optional_silence.txt<br>和4一样</li>
</ol>
<p>这个脚本本身只是将input文件夹下面的lexicon_nosil.txt，lexicon.txt， phones.txt复制到dict所在目录，并且加上SIL。</p>
<h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p>接下来要做语言模型。<br>项目提供了一个一元的语言模型。然而我们需要将这个模型转换成一个WFST（一种有穷自动机）<br>执行:<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">utils/prepare_lang.sh --position-dependent-phones <span class="literal">false</span> data/local/dict/ <span class="string">&quot;&lt;SIL&gt;&quot;</span> data/local/lang/ data/lang</span><br><span class="line"><span class="built_in">local</span>/prepare_lm.sh</span><br></pre></td></tr></table></figure></p>
<p>prepare_lang.sh的开头注释如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># This script prepares a directory such as data/lang/, in the standard format,</span><br><span class="line"># given a source directory containing a dictionary lexicon.txt in a form like:</span><br><span class="line"># word phone1 phone2 ... phoneN</span><br><span class="line"># per line (alternate prons would be separate lines), or a dictionary with probabilities</span><br><span class="line"># called lexiconp.txt in a form:</span><br><span class="line"># word pron-prob phone1 phone2 ... phoneN</span><br><span class="line"># (with 0.0 &lt; pron-prob &lt;= 1.0); note: if lexiconp.txt exists, we use it even if</span><br><span class="line"># lexicon.txt exists.</span><br><span class="line"># and also files silence_phones.txt, nonsilence_phones.txt, optional_silence.txt</span><br><span class="line"># and extra_questions.txt</span><br><span class="line"># Here, silence_phones.txt and nonsilence_phones.txt are lists of silence and</span><br><span class="line"># non-silence phones respectively (where silence includes various kinds of</span><br><span class="line"># noise, laugh, cough, filled pauses etc., and nonsilence phones includes the</span><br><span class="line"># &quot;real&quot; phones.)</span><br><span class="line"># In each line of those files is a list of phones, and the phones on each line</span><br><span class="line"># are assumed to correspond to the same &quot;base phone&quot;, i.e. they will be</span><br><span class="line"># different stress or tone variations of the same basic phone.</span><br><span class="line"># The file &quot;optional_silence.txt&quot; contains just a single phone (typically SIL)</span><br><span class="line"># which is used for optional silence in the lexicon.</span><br><span class="line"># extra_questions.txt might be empty; typically will consist of lists of phones,</span><br><span class="line"># all members of each list with the same stress or tone; and also possibly a</span><br><span class="line"># list for the silence phones.  This will augment the automatically generated</span><br><span class="line"># questions (note: the automatically generated ones will treat all the</span><br><span class="line"># stress/tone versions of a phone the same, so will not &quot;get to ask&quot; about</span><br><span class="line"># stress or tone).</span><br></pre></td></tr></table></figure>
<p>通过阅读脚本和脚本中的注释。可以知道<code>prepare_lang.sh</code>的用法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Usage: utils/prepare_lang.sh &lt;dict-src-dir&gt; &lt;oov-dict-entry&gt; &lt;tmp-dir&gt; &lt;lang-dir&gt;</span><br><span class="line">e.g.: utils/prepare_lang.sh data/local/dict &lt;SPOKEN_NOISE&gt; data/local/lang data/lang</span><br><span class="line">--position-dependent-phones (true|false)        # default: true; if true, use _B, _E, _S &amp; _I</span><br></pre></td></tr></table></figure>
<p><dict-src-dir>是我们在上一部分生成的词典目录。需要包含lexico.txt，extra_questions.txt，nonsilence_phones.txt，optional_silence.txt  silence_phones.txt。<br><code>position_dependent_phones</code>参数为false，导致解码后不能算出单词边界。很多的脚本，特别是评分脚本将不能正常运行。<br>第二个指令将语言模型转换成G.fst格式并保存在data&#x2F;lang_test_tg 目录下。<br>这个脚本的核心内容是调用了arpa2fst和fstisstochastic，再创建了G.fst之后检查是否有空字符（<s>,</s>之类的）的循环。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arpa2fst --disambig-symbol=#0 --read-symbol-table=$test/words.txt input/task.arpabo $test/G.fst</span><br><span class="line"></span><br><span class="line">fstisstochastic $test/G.fst</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yutianzuijin/article/details/78756130">arpa2fst 原理详解</a></p>
<blockquote>
<p>arpa文件可以很容易地表示任意n-gram语言模型，不过在实际中n通常等于3、4或者5。arpa文件的每一行表示一个文法项，它通常包含三部分内容：probability word(s) [backoff probability]。probability表示该词或词组发生的概率，word(s)表示具体的词或者词组。backoff probablitiy是可选项，表示回退概率。</p>
</blockquote>
<p>在yesno这个toy project中只使用1元的语言模型。对应的arpa文件在<code>input/task.arpabo</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">\data\</span><br><span class="line">ngram 1=4</span><br><span class="line"></span><br><span class="line">\1-grams:</span><br><span class="line">-1	NO</span><br><span class="line">-1	YES</span><br><span class="line">-99 &lt;s&gt;</span><br><span class="line">-1 &lt;/s&gt;</span><br><span class="line"></span><br><span class="line">\end\</span><br></pre></td></tr></table></figure>
<p>fstisstochastic命令则如同其名字的含义一样，用来检查G.fst是否是随机的。<br>在<code>s5/data/lang</code>目录下会出现：</p>
<ol>
<li><code>phones.txt</code>:将phone转换成数字。其中#0，#1是空字，用来表示句子的开头和结尾。<eps> 是一个特别的含义表示这个弧上没有符号。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;eps&gt; 0</span><br><span class="line">SIL 1</span><br><span class="line">Y 2</span><br><span class="line">N 3</span><br><span class="line">#0 4</span><br><span class="line">#1 5</span><br></pre></td></tr></table></figure></li>
<li><code>words.txt</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;eps&gt; 0</span><br><span class="line">&lt;SIL&gt; 1</span><br><span class="line">NO 2</span><br><span class="line">YES 3</span><br><span class="line">#0 4</span><br><span class="line">&lt;s&gt; 5</span><br><span class="line">&lt;/s&gt; 6</span><br></pre></td></tr></table></figure></li>
<li><code>L_disambig.fst, L.fs</code>t: the dict can be recognized by Kaldi</li>
<li><code>topo</code>: phone states transition(HMM)</li>
<li><code>oov</code>: out of vocabulary. 仅包含<code>&lt;SIL&gt;</code></li>
<li><code> phones</code>: some information about phones</li>
</ol>
<h2 id="特征提取和训练"><a href="#特征提取和训练" class="headerlink" title="特征提取和训练"></a>特征提取和训练</h2><p>MFCC特征提取和GMM-HMM建模</p>
<p>提取梅尔倒谱系数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">steps/make_mfcc.sh --nj $num $input_dir $log_dir $output_dir</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/60371062">语音信号处理（二）—— MFCC详解</a><br>梅尔倒谱系数是一种非线性的时频表示法，其应用了人耳对低频声音的听觉敏感度更高的原理。</p>
<p>接着正则化倒谱特征</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">steps/compute_cmvn_stats.sh </span><br><span class="line">utils/fix_data_dir.sh $input_dir</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://placebokkk.github.io/kaldi/2019/08/05/asr-kaldi-feat2.html">Kaldi中的特征提取(二）- 特征变换</a><br>对训练集和测试集做同样的操作。<br>这里我采用的参数是 $num&#x3D;1 $output_dir&#x3D;mfcc<br>那么结果将会保存在mfcc文件夹下。<br>cmvn_test_yesno.ark  cmvn_test_yesno.scp  cmvn_train_yesno.ark  cmvn_train_yesno.scp。<br>ark文件包含特征向量（用cat打开是乱码），scp文件是关系文件，从发音者到ark文件的对应。<br>也可以直接跑脚本：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">num=1 </span><br><span class="line">output_dir=mfcc</span><br><span class="line">for x in train_yesno test_yesno; do</span><br><span class="line">  steps/make_mfcc.sh --nj 1 data/$x exp/make_mfcc/$x mfcc  </span><br><span class="line">  steps/compute_cmvn_stats.sh data/$x exp/make_mfcc/$x mfcc        </span><br><span class="line">  utils/fix_data_dir.sh data/$x </span><br><span class="line">done </span><br></pre></td></tr></table></figure>
<h2 id="单音素模型训练"><a href="#单音素模型训练" class="headerlink" title="单音素模型训练"></a>单音素模型训练</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">steps/train_mono.sh —nj $N —cmd $MAIN_CMD $DATA_DIR $LANG_DIR $OUTPUT_DIR</span><br></pre></td></tr></table></figure>
<p>参数说明：<br>—nj：job的数量，来自同一个speaker的语音不能并行处理。所以在本项目中只能选择为1。<br>—cmd：为了使用本机的资源，调用”utils&#x2F;run.pl”</p>
<p>运行脚本：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_cmd=&quot;utils/run.pl&quot; steps/train_mono.sh --nj 1 --cmd &quot;$train_cmd&quot; \   </span><br><span class="line">--totgauss 400 \   </span><br><span class="line">data/train_yesno data/lang exp/mono0a</span><br></pre></td></tr></table></figure>
<p>到现在我们已经完成了模型的训练。</p>
<h2 id="解码和测试"><a href="#解码和测试" class="headerlink" title="解码和测试"></a>解码和测试</h2><p>接下来用测试集来验证一下模型的准确与否。<br>第一步是创建一个全连接的FST网络。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">utils/mkgraph.sh data/lang_test_tg exp/mono0a exp/mono0a/graph_tgpr</span><br></pre></td></tr></table></figure>
<p>这个指令背后的脚本很长。基本上做的事情是创建以一个HCLG（HMM+Context+Lexicon+Grammer）的解码器并保存在exp&#x2F;mono0a&#x2F;graph_tgpr中。<br>还记得我们的每一条语音都是8个连续的Ken或Lo吗(Ken，Lo是希伯来语的yes no）?训练好的模型的工作就是找出这8个词的顺序。<br><code>steps/decode.sh [options] &lt;graph-dir&gt; &lt;data-dir&gt; &lt;decode-dir&gt;</code>用来寻找每一个测试音频的最佳路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decode_cmd=&quot;utils/run.pl&quot; steps/decode.sh --nj 1 --cmd &quot;$decode_cmd&quot; \</span><br><span class="line">exp/mono0a/graph_tgpr data/test_yesno exp/mono0a/decode_test_yesno </span><br></pre></td></tr></table></figure>
<p>最后是查看结果的环节。<br>在decode.sh内部最后会调用score.sh，这个脚本则生成预测的结果并且计算测试集Word error rate（WER）。<br>调用下列命令可以看到最好的效果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for x in exp/*/decode*; do [ -d $x ] &amp;&amp; grep WER $x/wer_* | utils/best_wer.sh;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%WER 0.00 [ 0 / 232, 0 ins, 0 del, 0 sub ] exp/mono0a/decode_test_yesno/wer_10_0.0</span><br></pre></td></tr></table></figure>
<p>解读一下结果，花了很长时间才弄懂这些东西是什么意思。<br>WER后跟着的0.00是说字的错误率为0，即准确率为100%。<br>测试集一共29条音频，每条音频有8个字（单音素的字）。一共232个字。<br>参考Stanford的cs224s-17.lec04.pdf</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4328467-dc5c0fcaf24b3750.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="WER的计算方法"><br><img src="https://upload-images.jianshu.io/upload_images/4328467-1c85e0672f7772cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"><br>而wer结果文件中的10和0.0分别是lmwt(Language Weight)和wip(word insertion penalty，词插入惩罚)。lmwt用来平衡LM（语言模型）在多大程度上帮助AM（语音模型）<img src="https://upload-images.jianshu.io/upload_images/4328467-3e2341231bb987fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="LMWT用途 
https://skemman.is/bitstream/1946/31280/1/msc_anna_vigdis_2018.pdf"><br>至于<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/31416764/answer/353868805">wip</a>：</p>
<blockquote>
<p>word insertion penalty, 简写WIP, 是HMM识别匹配过程中用于设置句长的一个参数，可以用来调节生成句子中的单词个数，当前主流的语音识别系统主要采用的都是音素识别，即根据单词的音标而不是单词来进行匹配，这就导致了，在识别过程中，可能很难确定单词的gap，如果让系统自由识别，根据参数初始化的模型来进行匹配的话有可能会生成一些诡异的由长单词构成的句子，或者有很多短单词构成的句子，这些匹配率很低的句子对HMM参数的优化作用很小，同时也很大概率会导致学习速率奇慢或者局部最优解这样的问题，所以通过设置这个参数来得到一些更符合语义结构的生成片段。</p>
</blockquote>
<p>最后，我们调用的所有脚本都在run.sh中。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/05/01/Kaldi%E5%85%A5%E9%97%A8-%E4%B8%80-yesno%E9%A1%B9%E7%9B%AE/" data-id="clnhnlj080001zox1g62x6j4y" data-title="Kaldi入门(一):yesno项目" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ASR/" rel="tag">ASR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaldi/" rel="tag">Kaldi</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-python程序同步webdav网盘（坚果云、owncloud）" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/01/10/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%EF%BC%88%E5%9D%9A%E6%9E%9C%E4%BA%91%E3%80%81owncloud%EF%BC%89/" class="article-date">
  <time class="dt-published" datetime="2020-01-10T03:58:06.000Z" itemprop="datePublished">2020-01-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2020/01/10/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%EF%BC%88%E5%9D%9A%E6%9E%9C%E4%BA%91%E3%80%81owncloud%EF%BC%89/">python程序同步webdav网盘（坚果云、owncloud)</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在编写一个Django项目的时候有定时备份数据文件的需求。因为项目运行在云服务器中，担心的是服务器挂掉，所以备份的地方不能是同一台服务器。在这个项目里自己去建一个服务器来管理备份数据显得没有必要。目前网络存储提供商有许多家，我选取的方案是编写python定时程序连接支持WebDAV协议的网盘，例如坚果云和owncloud。</p>
<p>分为两部分：</p>
<ol>
<li>Python同步代码编写</li>
<li>Django定时任务编写</li>
</ol>
<h2 id="Python同步代码编写"><a href="#Python同步代码编写" class="headerlink" title="Python同步代码编写"></a>Python同步代码编写</h2><p>使用<a target="_blank" rel="noopener" href="https://pypi.org/project/webdavclient3/">webdavclient3</a>库来处理webDAV协议的部分。先安装：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install webdavclient3</span><br></pre></td></tr></table></figure>

<p>然后在自己的项目的某个地方建立一个py文件。我选的是<code>[项目目录]\utils\backup\backup.py</code></p>
<p>编写python代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> webdav3.client <span class="keyword">import</span> Client</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> webdav3.exceptions <span class="keyword">import</span> LocalResourceNotFound</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="comment"># invoke this function every day.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">upload</span>():</span><br><span class="line">    options = &#123;</span><br><span class="line">        <span class="string">&#x27;webdav_hostname&#x27;</span>: <span class="string">&quot;网盘地址，如果是坚果云，不能只输入/dav/路径，似乎这个文件夹不能访问，在下面再建一个文件夹，比如backup。网址中需要有backup的地址比如https://dav.jianguoyun.com/dav/backup&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;webdav_login&#x27;</span>: <span class="string">&quot;用户名&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;webdav_password&#x27;</span>: <span class="string">&quot;密码，如果是坚果云填写应用密码&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;disable_check&#x27;</span>: <span class="literal">True</span>, <span class="comment">#有的网盘不支持check功能</span></span><br><span class="line">    &#125;</span><br><span class="line">    client = Client(options)</span><br><span class="line">		<span class="comment"># 我选择用时间戳为备份文件命名</span></span><br><span class="line">    file_name = <span class="built_in">str</span>(math.floor(datetime.now().timestamp())) + <span class="string">&#x27;.bak&#x27;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 写死的路径，第一个参数是网盘地址</span></span><br><span class="line">        client.upload(<span class="string">&#x27;backup/&#x27;</span> + file_name, <span class="string">&#x27;本地地址，绝对路径&#x27;</span>)</span><br><span class="line">        <span class="comment"># 打印结果，之后会重定向到log</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;upload at &#x27;</span> + file_name)</span><br><span class="line">    <span class="keyword">except</span> LocalResourceNotFound <span class="keyword">as</span> exception:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;An error happen: LocalResourceNotFound ---&#x27;</span>  + file_name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果是直接调用文件，执行upload()</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;run upload&#x27;</span>)</span><br><span class="line">    upload()</span><br></pre></td></tr></table></figure>

<p>Python的代码相对简短。只需要在服务器的命令行执行<code>python upload.py</code>，备份文件自动上传到网盘。然而还不完整，这个程序的目的是定期执行。接下来结合Django的定期执行接口做到每日备份。</p>
<h2 id="Django定时任务编写"><a href="#Django定时任务编写" class="headerlink" title="Django定时任务编写"></a>Django定时任务编写</h2><p>Django是目前很流行的python web服务框架。通过django自带的命令创建project和app（这一部分不讲）。</p>
<p>当项目建好后，使用<code>python manage.py</code>可以运行项目、数据库代码整合。开发者可以通过继承BaseCommand类来自定义命令，然后再通过django_crontab定期执行命令。或者不通过自定义命令，直接使用django_crontab定期执行函数。</p>
<h3 id="创建backupCmd命令"><a href="#创建backupCmd命令" class="headerlink" title="创建backupCmd命令"></a>创建backupCmd命令</h3><p>在之前创建的app下新建management&#x2F;commands目录，在该目录下新建<code>backupCmd.py</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from django.core.management.base import BaseCommand</span><br><span class="line">from utils.backup.backup import upload</span><br><span class="line"></span><br><span class="line">class Command(BaseCommand):</span><br><span class="line">    def handle(self, *args, **options):</span><br><span class="line">        upload()</span><br></pre></td></tr></table></figure>

<p>当完成后，在项目根目录下执行<code>python manage.py backupCmd</code>就可以单次执行程序了。</p>
<p>在setting.py尾部添加:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 运行定时函数，每天1点运行。</span><br><span class="line">CRONJOBS = [</span><br><span class="line">    (&#x27;0 01 * * *&#x27;, &#x27;utils.backup.backup&#x27;,&#x27;&gt;&gt; ~/test_crontab.log&#x27;)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 运行定时命令， </span><br><span class="line">CRONJOBS = [</span><br><span class="line">    (&#x27;*/1 * * * *&#x27;, &#x27;django.core.management.call_command&#x27;, [&#x27;backupCmd&#x27;], &#123;&#125;, &#x27;&gt;&gt; ~/test_crontab.log&#x27;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>然后执行<code>python manage.py crontab add</code>，定时任务加入其中。</p>
<p>当时间到达的时候，程序将自动运行。日志会输出到<code>~/test_crontab.log</code>中。</p>
<p>linux中的定时任务crontab的语法如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*  *  *  *  * command</span><br><span class="line">分钟(0-59) 小时(0-23) 每个月的哪一天(1-31) 月份(1-12) 周几(0-6) shell脚本或者命令</span><br></pre></td></tr></table></figure>



<p>对于使用到的网盘，希望能够付费支持一下。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mynote.ai/2020/01/10/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%EF%BC%88%E5%9D%9A%E6%9E%9C%E4%BA%91%E3%80%81owncloud%EF%BC%89/" data-id="clnhnlj1w000nzox16imedog3" data-title="python程序同步webdav网盘（坚果云、owncloud)" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ASR/" rel="tag">ASR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Coursera/" rel="tag">Coursera</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kaldi/" rel="tag">Kaldi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Leet-Code/" rel="tag">Leet Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Numpy/" rel="tag">Numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OpenCV/" rel="tag">OpenCV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Postgres/" rel="tag">Postgres</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA/" rel="tag">个人</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86/" rel="tag">知识管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/" rel="tag">编程记录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" rel="tag">软件测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E7%BB%B4/" rel="tag">运维</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%85%E8%AF%BB%E6%97%A5%E6%8A%A5/" rel="tag">阅读日报</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ASR/" style="font-size: 13.33px;">ASR</a> <a href="/tags/Coursera/" style="font-size: 10px;">Coursera</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Kaldi/" style="font-size: 13.33px;">Kaldi</a> <a href="/tags/Leet-Code/" style="font-size: 10px;">Leet Code</a> <a href="/tags/Linux/" style="font-size: 16.67px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/Postgres/" style="font-size: 10px;">Postgres</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/%E4%B8%AA%E4%BA%BA/" style="font-size: 16.67px;">个人</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86/" style="font-size: 10px;">知识管理</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">编程记录</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">计算机网络</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">软件测试</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 10px;">运维</a> <a href="/tags/%E9%98%85%E8%AF%BB%E6%97%A5%E6%8A%A5/" style="font-size: 10px;">阅读日报</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/02/18/20240218-%E6%95%A3%E6%AD%A5%E6%97%B6%E7%9A%84%E8%87%AA%E8%AF%B4%E8%87%AA%E8%AF%9D/">20240218-夜间散步时的自说自话</a>
          </li>
        
          <li>
            <a href="/2020/11/23/LeetCode26/">LeetCode26</a>
          </li>
        
          <li>
            <a href="/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/">学习Kaldi：中文Aishell项目（上）</a>
          </li>
        
          <li>
            <a href="/2020/11/23/%E4%BD%BF%E7%94%A8Python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/">使用Python开发桌面应用的一个体验</a>
          </li>
        
          <li>
            <a href="/2020/11/23/%E4%BB%A5Notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/">以Notion为基础的自我管理体系</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Chen min<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>