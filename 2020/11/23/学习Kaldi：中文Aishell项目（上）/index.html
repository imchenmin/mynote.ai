<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>学习Kaldi：中文Aishell项目（上） | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="这篇文章是学习Kaldi的第二篇。对应SUSTech CS310课程的Lab6和Lab7。第一篇里探索了如何对toy language（仅包含两个单音素单词）进行语言模型的建模。至于训练和解码的部分，时间条件和理解能力暂时不允许去整理。本篇文章的主要目标是理解复杂的中文多音素语言模型和使用AiShell语料集来真实的训练出一个可用的中文语音识别模型。完整的AiShell例子包含GMM-HMM和神经">
<meta property="og:type" content="article">
<meta property="og:title" content="学习Kaldi：中文Aishell项目（上）">
<meta property="og:url" content="http://example.com/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="这篇文章是学习Kaldi的第二篇。对应SUSTech CS310课程的Lab6和Lab7。第一篇里探索了如何对toy language（仅包含两个单音素单词）进行语言模型的建模。至于训练和解码的部分，时间条件和理解能力暂时不允许去整理。本篇文章的主要目标是理解复杂的中文多音素语言模型和使用AiShell语料集来真实的训练出一个可用的中文语音识别模型。完整的AiShell例子包含GMM-HMM和神经">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/1246.png">
<meta property="og:image" content="http://example.com/images/1247.png">
<meta property="og:image" content="http://example.com/images/1248.png">
<meta property="og:image" content="http://example.com/images/1249.png">
<meta property="og:image" content="http://example.com/images/1250.png">
<meta property="og:image" content="http://example.com/images/1251.png">
<meta property="og:image" content="http://example.com/images/1252.png">
<meta property="og:image" content="http://example.com/images/1253.png">
<meta property="og:image" content="http://example.com/images/1254.png">
<meta property="og:image" content="http://example.com/images/1255.png">
<meta property="og:image" content="http://example.com/images/1256.png">
<meta property="og:image" content="http://example.com/images/1257.png">
<meta property="og:image" content="http://example.com/images/1258.png">
<meta property="article:published_time" content="2020-11-23T11:36:51.000Z">
<meta property="article:modified_time" content="2020-11-28T16:23:31.380Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Kaldi">
<meta property="article:tag" content="ASR">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/1246.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-学习Kaldi：中文Aishell项目（上）" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/" class="article-date">
  <time class="dt-published" datetime="2020-11-23T11:36:51.000Z" itemprop="datePublished">2020-11-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      学习Kaldi：中文Aishell项目（上）
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>这篇文章是学习Kaldi的第二篇。对应SUSTech CS310课程的Lab6和Lab7。<br>第一篇里探索了如何对toy language（仅包含两个单音素单词）进行语言模型的建模。至于训练和解码的部分，时间条件和理解能力暂时不允许去整理。<br>本篇文章的主要目标是理解复杂的中文多音素语言模型和使用AiShell语料集来真实的训练出一个可用的中文语音识别模型。完整的AiShell例子包含GMM-HMM和神经网络。Lab6先展示了GMM-HMM后的结果。Lab7则补充了神经网络。</p>
<h2 id="AiShell描述和下载"><a href="#AiShell描述和下载" class="headerlink" title="AiShell描述和下载"></a>AiShell描述和下载</h2><p>AiShell 是 ？？公司开源的中文普通话语料集。400个来自不同方言区的人参与录制， 录制的条件是在室内使用高保真的麦克风，音频降采样到16000Hz。<br>&#x2F;&#x2F;中文文字脚本95%的准确度<br>&#x2F;&#x2F;170小时的语料。划分为85%的训练集，10%的开发集（作用？），5%的测试集。在上课的时候我被录制语料的成本吓到了，2000小时的语料大约需要100万人民币的费用。<br>AiShell语料集可以免费由于学术目的。</p>
<p>语料集下载<br>Kaldi中包含Aishell的示例脚本。在<code>kaldi/egs/aishell/s5</code>中。下文所有的文件都在该目录之下。<br>下载语料集的脚本包含在<code>run.sh</code>中。<br>先安装好语言模型的工具才能运行<code>run.sh</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run ./install_kaldi_lm.sh &amp;&amp; source ../env.sh</span><br></pre></td></tr></table></figure>
<p>上一篇文章没有说每一个项目下的s5文件夹中有什么，在网上找到了别人写的一个总结：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6ab663601da8">kaldi 源码分析(三) - run.pl 分析</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cmd.sh                     # 并行执行命令，通常分 run.pl, queue.pl 两种</span><br><span class="line">config                       # 参数定制化配置文件， mfcc, decode, cmvn 等配置文件</span><br><span class="line">local                         # 工程定制化内容</span><br><span class="line">path.sh                    # 环境变量相关脚本</span><br><span class="line">run.sh                      # 整体流程控制脚本，主入口脚本</span><br><span class="line">steps                       # 存放单一步骤执行的脚本</span><br><span class="line">utils                         # 存放解析文件，预处理等相</span><br><span class="line">关工具的脚本</span><br></pre></td></tr></table></figure>
<p>最重要的入口脚本是run.sh。包含所有脚本。如果要在本地运行，需要修改这个脚本。把其中的<code>queue.pl</code>改成<code>run.pl</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export train_cmd=&quot;run.pl&quot; </span><br><span class="line">export decode_cmd=run.pl </span><br><span class="line">export mkgraph_cmd=&quot;run.pl&quot;</span><br></pre></td></tr></table></figure>
<p>先做Lab6，注释掉神经网络训练部分。为了对比加不加神经网络对最后的识别准确率有多大的影响。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># nnet3</span><br><span class="line">#local/nnet3/run_tdnn.sh</span><br><span class="line"># chain</span><br><span class="line">#local/chain/run_tdnn.sh</span><br></pre></td></tr></table></figure>



<h2 id="运行run-sh脚本，一步到位"><a href="#运行run-sh脚本，一步到位" class="headerlink" title="运行run.sh脚本，一步到位"></a>运行run.sh脚本，一步到位</h2><p>在上一篇文章中，主要讲了kaldi的工作流程，复杂一点的项目除了要考虑多音素的对齐以外？基本流程是差不多的。先运行整体流程脚本run.sh看一下效果。然后再具体深入进脚本中看有哪些关键步骤。</p>
<p>你是否遇到过连接远程服务器跑训练，然后网络掉线杀掉了正在跑的进程？我遇到过，后来主要使用nohup来避免这个问题。课件里推荐使用screen来避免远程登陆进程被杀掉后，训练进程也停止的问题。screen的原理不是本篇文章关心的重点。<br>加上screen后运行run.sh：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">screen -S run</span><br><span class="line">run ./run.sh</span><br></pre></td></tr></table></figure>
<p>就能看到脚本在一个新的页面输出内容了。<br>如果要结束进程<code> ctrl a + d</code>&#x2F;&#x2F;我其实不喜欢这个命令，因为很经常使用ctrl+a来编辑命令，两个快捷键冲突。</p>
<h2 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h2><p>中文语音识别的准确度通常使用CER（Char Error Rate）来表示。因为中文中字是最小语义单位，而英文中词是基本语义单位。<br>和上一篇文章差不多的命令。脚本的运行结果保存在了exp目录下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for x in exp/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br></pre></td></tr></table></figure>
<p>训练出来的结果如下：<br><img src="/images/1246.png" alt="训练结果"></p>
<p>可以<code>cat RESULTS</code>，和官方跑出来的结果做一下对比。<br><img src="/images/1247.png" alt="RESULTS"><br>需要注意的是，和上篇文章的实验不一样的是，输出的结果是多行的，因为执行了多次的实验，上面的脚本输出的是每次实验最好的结果。<br>我自己跑出来的最好结果是tri5a的cer_14_0.5而RESULTS中的GMM-HMM模型中最好的结果是tri5a的cer_13_0.5。两者CER都是12.12。每次实验本身都有一定的随机性。结果有一些误差是没问题的。为了确认模型有被正确的训练，查看自己结果的<code>tri5a/decode_test/cer_13_0.5</code>的CER是12.18，恰好不是最优解而已。这里的13和14是lmwt（语言模型权重）。具体的可以看上一篇文章。<br><img src="/images/1248.png" alt="cer_13_0.5"></p>
<h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><p>使用命令<code>cat run.sh | grep &quot;#&quot;</code>将run.sh脚本中的环节注释提取打印出来。其中倒数2，4行是我们在一开始注释掉的。可以看到基本可以分为准备、训练和获取结果三个部分。<br><img src="/images/1249.png" alt="run.sh注释部分"></p>
<h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><ol>
<li>下载语料集<br>需要注意的是aishell语料集有大概20GB的大小。意味着需要很长的时间才能下载下来。我是直接用服务器里提前下好的语料集。<br><img src="/images/1250.png" alt="aishell目录概览"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/download_and_untar.sh $data $data_url data_aishell || exit 1;</span><br></pre></td></tr></table></figure>
这里的 <code>a || b</code>是一个逻辑符号，代表着如果a执行失败则执行b。这里要放一个小插曲。去年面试阿里云的实习项目时，面试官开头就问了如何知道上一条linux命令是否成功执行。我当时不知道，现在要知道了。就是看变量<code>$?</code>的值，如果为0代表成功执行。这里的<code>exit 1</code>终止当前进程并且将<code>$?</code>设置为1。表示不成功执行。<br><code>$data</code> 是aishell在本机的位置，既可以新建一个空目录来下载，也可以指定到已经下好的路径，aishell 分为<code>resource_aishell</code>和<code>data_aishell</code>两部分来下载，脚本会通过检查每一个部分下是否有<code>.complete</code>文件来判断当前部分是否下载完全。如果没有才会到指定网址下载。</li>
<li>Lexicon Preparation<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/aishell_prepare_dict.sh $data/resource_aishell || exit 1;</span><br></pre></td></tr></table></figure>
这个脚本的功能主要是将<code>resource_aishell</code>下的<code>lexicon.txt</code>复制到<code>data/local/dict</code>中。并且提取出<code>nonsilence_phones.txt</code>、<code>optional_silence.txt   </code>、<code>silence_phones.txt</code>和<code>extra_questions.txt</code>。用到了很多awk和perl的脚本。没看懂。（要是看懂了，第一次assignment就不会搞砸了）<br>那就要求自己看懂把。</li>
</ol>
<p><img src="/images/1251.png" alt="lexicon.txt"></p>
<p><img src="/images/1252.png" alt="提取extra_questions.txt的代码"></p>
<p><img src="/images/1253.png" alt="extra_questions.txt部分内容"></p>
<p><img src="/images/1254.png" alt="提取nonsilence_phones.txt代码"><br>每行代表一组相同的base phone,包含各种不同的重音或者声调。<br><img src="/images/1255.png" alt="nonsilence_phones.txt部分内容"></p>
<ol start="3">
<li>Data preparation<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/aishell_data_prep.sh $data/data_aishell/wav $data/data_aishell/transcript || exit 1;</span><br></pre></td></tr></table></figure>
<code>$data/data_aishell/wav</code>目录下放着的是音频文件。其中有两级目录<code>speaker/filename.wav</code>。<br><code>$data/data_aishell/transcript</code>目录下放着的是<code>aishell_transcript_v0.8.txt</code>文字翻录。<br>这个shell脚本的功能是将<code>$data/data_aishell/wav</code>下的 <code>train</code>,<code>test</code>,<code>dev</code>分别建立索引。并且建立Kaldi能够理解的语料格式。具体有些什么可以参考上一篇文章和下面这一段脚本。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Transcriptions preparation</span><br><span class="line">for dir in $train_dir $dev_dir $test_dir; do</span><br><span class="line">  echo Preparing $dir transcriptions</span><br><span class="line">  # 将当前集合目录下的wav的文件名提取出来作为utt_id</span><br><span class="line">  sed -e &#x27;s/\.wav//&#x27; $dir/wav.flist | awk -F &#x27;/&#x27; &#x27;&#123;print $NF&#125;&#x27; &gt; $dir/utt.list</span><br><span class="line">  # 根据目录结构建立utt2spk的关系</span><br><span class="line">  sed -e &#x27;s/\.wav//&#x27; $dir/wav.flist | awk -F &#x27;/&#x27; &#x27;&#123;i=NF-1;printf(&quot;%s %s\n&quot;,$NF,$i)&#125;&#x27; &gt; $dir/utt2spk_all</span><br><span class="line">  # 按列合并utt.list和wav.flist，达到对音频文件的映射。</span><br><span class="line">  paste -d&#x27; &#x27; $dir/utt.list $dir/wav.flist &gt; $dir/wav.scp_all</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $aishell_text &gt; $dir/transcripts.txt</span><br><span class="line">  awk &#x27;&#123;print $1&#125;&#x27; $dir/transcripts.txt &gt; $dir/utt.list</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $dir/utt2spk_all | sort -u &gt; $dir/utt2spk</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $dir/wav.scp_all | sort -u &gt; $dir/wav.scp</span><br><span class="line">  sort -u $dir/transcripts.txt &gt; $dir/text</span><br><span class="line">  utils/utt2spk_to_spk2utt.pl $dir/utt2spk &gt; $dir/spk2utt</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="4-Phone-sets-questions-L-compilation"><a href="#4-Phone-sets-questions-L-compilation" class="headerlink" title="4. Phone sets, questions, L compilation"></a>4. Phone sets, questions, L compilation</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">utils/prepare_lang.sh --position-dependent-phones false data/local/dict \</span><br><span class="line">    &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang data/lang || exit 1;</span><br></pre></td></tr></table></figure>
<p>上面shell脚本的目的是创建L.fst，音素模型，其中fst是Finite State Transducers（有限状态转换器）的缩写。找到这篇<a target="_blank" rel="noopener" href="https://blog.csdn.net/DuishengChen/article/details/52473918">Kaldi学习笔记 – 构建字典FST脚本 – prepare_lang.sh 关键内容解析</a>详细的说明了这个脚本的工作。而<a target="_blank" rel="noopener" href="https://blog.csdn.net/mengjianmuzi/article/details/99499343">关于prepare_lang的一点理解</a>给脚本进行了一些翻译和注释。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4ad2add56b25">Kaldi中FST(Finite State Transducer)含义及其可视化</a><br>L.fst: 音素词典（Phonetic Dictionary or Lexicon）模型，phone symbols作为输入，word symbols作为输出，如图Figure 1所示。<br><img src="/images/1256.png" alt="Figure 1 L.fst结构"><br>L_disambig.fst是为了消除模棱两可（disambiguation）而引入的模型，表述为 the lexicon with disambiguation symbols。分歧的情况如：一个词是另一个词的前缀，cat 和 cats在同一个词典中，则需要”k ae t #1”； 有同音的词，red: “r eh d #1”, read: “r eh d #2”。</p>
</blockquote>
<p>我一直疑惑<code>lexiconp.txt</code>是怎么生成的，查了好久。结果竟然只是一段在词和音素之间插入1.0的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if [[ ! -f $srcdir/lexiconp.txt ]]; then</span><br><span class="line">  echo &quot;**Creating $srcdir/lexiconp.txt from $srcdir/lexicon.txt&quot;</span><br><span class="line">  perl -ape &#x27;s/(\S+\s+)(.+)/$&#123;1&#125;1.0\t$2/;&#x27; &lt; $srcdir/lexicon.txt &gt; $srcdir/lexiconp.txt || exit 1;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p><img src="/images/1257.png" alt="lexiconp.txt"><br>那么L.fst是怎么得到的呢？<br>通过<code>make_lexicon_fst.py</code>（现有的博客都说是.pl结尾，可能kaldi重构了）。还有一个消歧义的过程。具体的就看不懂了。<a target="_blank" rel="noopener" href="https://shiweipku.gitbooks.io/chinese-doc-of-kaldi/content/decoding_graph_test.html">解码图创建示例（测试阶段）</a>里有较为详细的文档讲解。</p>
<h4 id="5-LM-training"><a href="#5-LM-training" class="headerlink" title="5. LM training"></a>5. LM training</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/aishell_train_lms.sh || exit 1;</span><br></pre></td></tr></table></figure>
<p>这个shell脚本读取<code>data/local/train/text</code>,<code>data/local/dict/lexicon.txt</code><br>得到text的计数文件<code>word.counts</code>并以<code>word.counts</code>为基础添加<code>lexicon.txt</code>中的字（除了SIL）出现的次数到<code>unigram.counts</code>中。我就没深入看下去了，期间用到的脚本文件有:<code>get_word_map.pl</code>、<code>train_lm.sh --arpa --lmtype 3gram-mincount $dir || exit 1</code>;这个步骤的结果保存在<code>data/local/lm/3gram-mincount/lm_unpruned.gz</code>中。</p>
<h4 id="6-G-compilation-check-LG-composition"><a href="#6-G-compilation-check-LG-composition" class="headerlink" title="6. G compilation, check LG composition"></a>6. G compilation, check LG composition</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">utils/format_lm.sh data/lang data/local/lm/3gram-mincount/lm_unpruned.gz \</span><br><span class="line">    data/local/dict/lexicon.txt data/lang_test || exit 1;</span><br></pre></td></tr></table></figure>
<p>这个步骤是编译G.fst并将LG串联起来。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/4ad2add56b25">Kaldi中FST(Finite State Transducer)含义及其可视化</a><br>G.fst: 语言模型，大部分是FSA（finite state acceptor, i.e. 每个arc的输入输出是相同的），如图Figure 2所示。<br><img src="/images/1258.png" alt="Figure 2 G.fst结构（由指令词识别1-gram语法产生，disambiguation symbol #0 未加入）
"></p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://hupeng.me/articles/25.html">kaldi 训练 aishell 解析</a><br>utils&#x2F;format_lm.sh:上述的语言工具基于第三方工具，为ARPA-format,脚本的作业是将其转换为fst，方便与之前的字典fst(L.fst)结合，发挥fst的优势。脚本最后会检测G.fst中是否存在没有单词的空回环，如果存在会报错，因为这会导致后续HLG determinization的出现错误。<br>脚本utils&#x2F;format_lm.sh解决把ARPA格式的语言模型转换成OpenFST格式类型。脚本用法如下：<br>Usage: utils&#x2F;format_lm.sh <lang_dir> <arpa-LM> <lexicon> <out_dir><br>E.g.: utils&#x2F;format_lm.sh data&#x2F;lang data&#x2F;local&#x2F;lm&#x2F;foo.kn.gz data&#x2F;local&#x2F;dict&#x2F;lexicon.txt data&#x2F;lang_test<br>Convert ARPA-format language models to FSTs.<br>这个脚本的一些关键命令如下：<br>Kaldi程序arpa2fst将ARPA格式的语言模型转换成一个加权有限状态转移机（实际上是接收机）。</p>
</blockquote>
<p>流程很复杂，未来可能再把L.fst，LM training，G.fst， LG composition另起一篇。（就是说现在时间条件不允许深入）</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>训练的环节开始我就读不懂了。主要是逻辑和概念不懂。也不浪费时间了。简单的去了解一下输入输出和功能。</p>
<h4 id="1-MFCC-特征生成"><a href="#1-MFCC-特征生成" class="headerlink" title="1. MFCC 特征生成"></a>1. MFCC 特征生成</h4><p>这个环节和yesno项目的没有不同。主要就是获得train,test, dev三个集合的归一化的梅尔倒谱系数。最后修复排序错误，并会移除那些被指明需要特征数据或标注，但是却找不到被需要的数据的那些发音（utterances）。</p>
<h4 id="2-训练单音素模型"><a href="#2-训练单音素模型" class="headerlink" title="2. 训练单音素模型"></a>2. 训练单音素模型</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">steps/train_mono.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/mono || exit 1;</span><br></pre></td></tr></table></figure>
<p>参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/82380716">kaldi-GMM-HMM pipeline</a>，上面的shell脚本主要是对齐音素和每一帧音频的。<a target="_blank" rel="noopener" href="https://blog.csdn.net/DanyHgc/article/details/75247158">Kaldi 入门train_mono.sh详解</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/DuishengChen/article/details/52575926">kaldi学习笔记 – 训练单音素（monophone）模型脚本 – steps&#x2F;train_mono.sh</a>都有讲一些。<br>对流程讲得最好的是：<br>mkgraph 需要 lang_test 下的 L.fst G.fst phones.txt, words.txt , phones&#x2F;silence.csl , phones&#x2F;<a href="https://link.zhihu.com/?target=http://disambig.int">http://disambig.int</a></p>
<p>以及 exp&#x2F;tri 下的 tree, final.mdl</p>
<blockquote>
<p>在训练的job并行训练过程中，训练数据的各个子集合是分散到不同的处理器去进行训练，然后每轮迭代后会进行合并。<br>下面就讲一下训练的过程：<br>1.首先是初始化GMM，使用的脚本是&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-init-mono，输出是0.mdl和tree文件；<br>2.compile training graphs,使用的脚本是&#x2F;kaldi-trunk&#x2F;source&#x2F;bin&#x2F;compile-training-graphs，输入是tree,0.mdl和L.fst,输出是fits.JOB.gz，其是在训练过程中构建graph的过程；<br>3.接下来是一个对齐的操作，kaldi-trunk&#x2F;source&#x2F;bin&#x2F;align-equal-compiled；<br>4.然后是基于GMM的声学模型进行最大似然估计得过程，脚本为&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-est；<br>5.然后进行迭代循环中进行操作，如果本步骤到了对齐的步骤，则调用脚本kaldi-kaldi&#x2F;src&#x2F;gmmbin&#x2F;gmm-align-compiled；<br>6.重新估计GMM，累计状态，用脚本&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-acc-states-ali；调用新生成的参数(高斯数)重新估计GMM，调用脚本&#x2F;kaldi-trunk&#x2F;src&#x2F;gmmbin&#x2F;gmm-est；<br>7.对分散在不同处理器上的结果进行合并，生成.mdl结果，调用脚本gmm-acc-sum；<br>8.增加高斯数，如果没有超过设定的迭代次数，则跳转到步骤5重新进行训练<br>最后生成的.mdl即为声学模型文件<br>在离线识别阶段，即可以调用utils&#x2F;mkgraph.sh；来对刚刚生成的声学文件进行构图<br>之后解码，得到离线测试的识别率。</p>
</blockquote>
<h4 id="3-Monophone-decoding-单音素解码"><a href="#3-Monophone-decoding-单音素解码" class="headerlink" title="3. (Monophone decoding) 单音素解码"></a>3. (Monophone decoding) 单音素解码</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">utils/mkgraph.sh data/lang_test exp/mono exp/mono/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/mono/graph data/dev exp/mono/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/mono/graph data/test exp/mono/decode_test</span><br></pre></td></tr></table></figure>
<p><code>mkgraph.sh</code>将L_disambig.fst 和 G.fst 复合生成LG.fst。中间经历了我看不懂的处理。最终生成用于解码的 HCLG.fst。</p>
<h4 id="看不懂的部分"><a href="#看不懂的部分" class="headerlink" title="看不懂的部分"></a>看不懂的部分</h4><p>后面就已经看不懂了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"># Get alignments from monophone system.</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/mono exp/mono_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># train tri1 [first triphone pass]</span><br><span class="line">steps/train_deltas.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/mono_ali exp/tri1 || exit 1;</span><br><span class="line"></span><br><span class="line"># decode tri1</span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri1 exp/tri1/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri1/graph data/dev exp/tri1/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri1/graph data/test exp/tri1/decode_test</span><br><span class="line"></span><br><span class="line"># align tri1</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri1 exp/tri1_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># train tri2 [delta+delta-deltas]</span><br><span class="line">steps/train_deltas.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/tri1_ali exp/tri2 || exit 1;</span><br><span class="line"></span><br><span class="line"># decode tri2</span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri2 exp/tri2/graph</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri2/graph data/dev exp/tri2/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri2/graph data/test exp/tri2/decode_test</span><br><span class="line"></span><br><span class="line"># train and decode tri2b [LDA+MLLT]</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri2 exp/tri2_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># Train tri3a, which is LDA+MLLT,</span><br><span class="line">steps/train_lda_mllt.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/tri2_ali exp/tri3a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri3a exp/tri3a/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri3a/graph data/dev exp/tri3a/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri3a/graph data/test exp/tri3a/decode_test</span><br><span class="line"></span><br><span class="line"># From now, we start building a more serious system (with SAT), and we&#x27;ll</span><br><span class="line"># do the alignment with fMLLR.</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri3a exp/tri3a_ali || exit 1;</span><br><span class="line"></span><br><span class="line">steps/train_sat.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line">  2500 20000 data/train data/lang exp/tri3a_ali exp/tri4a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri4a exp/tri4a/graph</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri4a/graph data/dev exp/tri4a/decode_dev</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri4a/graph data/test exp/tri4a/decode_test</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh  --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri4a exp/tri4a_ali</span><br><span class="line"></span><br><span class="line"># Building a larger SAT system.</span><br><span class="line"></span><br><span class="line">steps/train_sat.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line">  3500 100000 data/train data/lang exp/tri4a_ali exp/tri5a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri5a exp/tri5a/graph || exit 1;</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">   exp/tri5a/graph data/dev exp/tri5a/decode_dev || exit 1;</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">   exp/tri5a/graph data/test exp/tri5a/decode_test || exit 1;</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri5a exp/tri5a_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># nnet3</span><br><span class="line">local/nnet3/run_tdnn.sh</span><br><span class="line"></span><br><span class="line"># chain</span><br><span class="line">local/chain/run_tdnn.sh</span><br></pre></td></tr></table></figure>

<h3 id="获取结果"><a href="#获取结果" class="headerlink" title="获取结果"></a>获取结果</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># getting results (see RESULTS file)</span><br><span class="line">for x in exp/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br><span class="line">for x in exp/*/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure>
<p>和上一篇文章一样的步骤。<br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/09deba57f339">Kaldi入门：yesno项目</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/" data-id="clnhnlj2t0014zox142lo7eb4" data-title="学习Kaldi：中文Aishell项目（上）" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ASR/" rel="tag">ASR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaldi/" rel="tag">Kaldi</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/11/23/LeetCode26/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          LeetCode26
        
      </div>
    </a>
  
  
    <a href="/2020/11/23/%E4%BD%BF%E7%94%A8Python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">使用Python开发桌面应用的一个体验</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ASR/" rel="tag">ASR</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Coursera/" rel="tag">Coursera</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kaldi/" rel="tag">Kaldi</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Leet-Code/" rel="tag">Leet Code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Numpy/" rel="tag">Numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OpenCV/" rel="tag">OpenCV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Postgres/" rel="tag">Postgres</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA/" rel="tag">个人</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86/" rel="tag">知识管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/" rel="tag">编程记录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" rel="tag">软件测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%90%E7%BB%B4/" rel="tag">运维</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%85%E8%AF%BB%E6%97%A5%E6%8A%A5/" rel="tag">阅读日报</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ASR/" style="font-size: 13.33px;">ASR</a> <a href="/tags/Coursera/" style="font-size: 10px;">Coursera</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Kaldi/" style="font-size: 13.33px;">Kaldi</a> <a href="/tags/Leet-Code/" style="font-size: 10px;">Leet Code</a> <a href="/tags/Linux/" style="font-size: 16.67px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/OpenCV/" style="font-size: 10px;">OpenCV</a> <a href="/tags/Postgres/" style="font-size: 10px;">Postgres</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/%E4%B8%AA%E4%BA%BA/" style="font-size: 13.33px;">个人</a> <a href="/tags/%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86/" style="font-size: 10px;">知识管理</a> <a href="/tags/%E7%BC%96%E7%A8%8B%E8%AE%B0%E5%BD%95/" style="font-size: 10px;">编程记录</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">计算机网络</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">软件测试</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 10px;">运维</a> <a href="/tags/%E9%98%85%E8%AF%BB%E6%97%A5%E6%8A%A5/" style="font-size: 10px;">阅读日报</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/11/23/LeetCode26/">LeetCode26</a>
          </li>
        
          <li>
            <a href="/2020/11/23/%E5%AD%A6%E4%B9%A0Kaldi%EF%BC%9A%E4%B8%AD%E6%96%87Aishell%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%B8%8A%EF%BC%89/">学习Kaldi：中文Aishell项目（上）</a>
          </li>
        
          <li>
            <a href="/2020/11/23/%E4%BD%BF%E7%94%A8Python%E5%BC%80%E5%8F%91%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BD%93%E9%AA%8C/">使用Python开发桌面应用的一个体验</a>
          </li>
        
          <li>
            <a href="/2020/11/23/%E4%BB%A5Notion%E4%B8%BA%E5%9F%BA%E7%A1%80%E7%9A%84%E8%87%AA%E6%88%91%E7%AE%A1%E7%90%86%E4%BD%93%E7%B3%BB/">以Notion为基础的自我管理体系</a>
          </li>
        
          <li>
            <a href="/2020/11/23/Ubuntu-18-04%E9%9D%99%E6%80%81IP%E8%AE%BE%E7%BD%AE%E5%92%8C%E9%81%87%E5%88%B0%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E5%8D%A1%E9%97%AE%E9%A2%98/">Ubuntu 18.04静态IP设置和遇到的虚拟机网卡问题</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>